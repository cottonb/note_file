# 操作系统（Operating System, OS）

# 一些碎碎念

在开始讲操作系统之前，我想先把一些概念澄清一下

---

## 中断和异常

![image-20230901232057101](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.assets/image-20230901232057101.png)

![image-20230901231844824](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.assets/image-20230901231844824.png)

就王道上的来说，中断一般指外中断，而异常一般指内中断

划分这两类的标准是同步异步

外中断也称外部中断，即由硬件导致的中断，是cpu执行的代码外导致的中断，也就意味着不同步。而外中断又分为可屏蔽中断和不可屏蔽中断

内中断，也称异常，内部异常，是cpu执行代码内导致的中断，意味着同步，又分为

- 故障，指令执行导致的需要处理的事件，如除0，溢出，这并不意味着程序会终止，因为可以通过跳转到特定的处理程序（这个可以自己来写），处理完就回来了（非自愿的，可修复的）
- 自陷，也叫陷阱，是自己布置的，想要它发生的，让cpu跳到某个地方处理的状况（自愿的，可修复的）
- 终止，这个时候就出现硬件故障了，注意，硬件出现故障，但并没有分到外中断，为什么？因为即便硬件出现故障，也不是硬件发出故障消息引发外中断，而是cpu执行到那里，发现有问题，也就是说是同步的，而内外是根据是否同步来分的，所以终止是内中断，也就是异常里的。而硬件都故障了，操作系统是无法解决的，所以是不可修复的（非自愿，不可修复的）

而从上面的分析，我们也可以看出，外中断和终止都是硬件引起的，而故障和自陷是软件引起的，所以又可以归类为

- 硬中断/硬件中断
  - 外中断
  - 终止
- 软中断/软件中断
  - 故障
  - 自陷

---

## cmd的续行符

windows系统的续行符为

```c
^
//就是^加换行符
```

linux系统的续行符为

```c
\
//就是反斜杠加换行符
```

## 命令行终止

一半的程序执行到一半都可以用ctrl+c去终止，数据库也是一样

## 查看系统配置

在cmd使用systeminfo

![image-20221124105957799](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.assets/image-20221124105957799.png)



## 外存，硬盘概念的解释

首先**外存**，**硬盘**，也叫**磁盘**，咱们都知道它容量大，读取速度慢，但其实我之前对其理解是错误的——它不是像内存那样的芯片组成的（cache是由SRAM组成的，而内存是由DRAM组成的，而ROM是只读存储器，所以存放的是一些操作系统的东西，可以看到都没有讲到硬盘）。那硬盘是什么样的呢？什么叫盘？圆圆的平面叫盘，所以磁盘就是用磁记录信息，一直转，然后磁头读出的一个东西（所以光盘就是用光记录信息，一直转，然后一个头读出信息的一个东西）。那你从磁盘的运作方式你就可以感觉到，这玩意转得再快也比不过内存电子跑得快啊。所以尽量不要到外存读就是这样

还有，一个硬盘里面会有很多张盘，盘上下两面都可以用，但一次只能读某个面（应该硬盘输出是流的形式的原因，同时读就得并行输出了），所以我们要读某一扇区的某一柱面的信息时，如果不同面的扇区不交替摆放，而是放在物理空间意义上的同一个位置，那么我们转一圈就只能读出一个面的一个要的扇区，这样就得转好多圈了，太傻逼了，所以我们交替摆放同一扇区在不同的物理空间意义上的位置，这样我们一圈就能读完了

---

## 进程概念的提出

然后我们来讲一下内存和外存的关系，首先，所有文件（程序）都是存在外存的，也就是磁盘里，其次，程序经过编译后得到的东西也是存在外存的，最后程序编译后得到的东西只有放到内存里面，才能运行

这样我们就可以看到，程序，只是一个文件，告诉了计算机怎么做，但真正做事的东西，在内存里头，这个东西，就叫**进程**

或者这么来理解，你写了一个浏览器程序，然后开了两个浏览器，硬盘上的文件还是那个文件，只是内存里有两个由这个程序得到的东西罢了。再者，你开两个浏览器，你对一个浏览器操作，另一个浏览器会受影响吗？不会

这里我们就可以看到进程和程序这两个概念的不同，程序只是个文本，是静态的；进程是真正在运行的东西，它从程序那里抄来了执行的方法，然后运行时的数据之类的，都是存在被分配给自己的空间里的，别的进程抄了同一个程序，那也和我没关系，它有它自己的数据空间。这样我们就能很清楚的看到，进程的执行，需要在内存里分配好空间给它，它用来放执行的代码，运行时的数据，还有操作系统对进程控制所需要的信息，代码，等等。于是就有了这张名场面

![image-20220727163548523](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220727163548523.png)

内核内存就是操作系统用的部分。

---

咱再来说说什么是**内核**吧。这个概念我目前还不是很清楚，但也能说说。咱先来想想，如果操作系统，这个程序，地位和普通程序一样，一些敏感的指令，操作，大家都能用，那别的程序修改了操作系统怎么办？其次，指令大家都能用，那两个程序抢资源，争着用一个指令改同一个内存，或者抢外部设备，那操作系统也没法干涉了——指令大家都可以用嘛。所以我们要把操作系统的地位提高，所以有了特权模式和用户模式，特权模式就是内核态，用户模式就是用户态，用户想用一些敏感指令，那就得向内核发出请求，内核认为可以做，于是CPU就从用户态转向内核态，执行内核态才可以执行的指令

---

## 并行和并发的区别

再来说一下并行和并发的区别

并行是指同时进行两个或多个事件

而并发指的是在一段时间内，看起来能同时处理多个事件

并发不一定能同一时刻进行两个或多个事件，它可能只是以非常短的时间交替进行处理；而并行是真正意义上的同一时刻进行

---

## 存储的各种单位的概念

还有**扇区**，**磁盘块**，**页**，**段**，**块**的概念。首先，这些概念都是若干位（bit）组成的一个单位。

- 扇区是划分磁盘的一个单位。我们从磁盘读东西，都是以一个扇区作为单位来读的，比如说我要读一个字节，那我就要到这个字节所在的柱面，所在盘面和所在扇区，把这个扇区，这个弧段给读出来，然后再对整个读出来的东西进行处理后得到一个字节
- 磁盘块是文件占据空间大小的最小单位。这个最小不是指文件的信息的最小单位，不是字节之类，而是文件想要在硬盘上占据空间，它只能一块一块空间地占据，这一块的大小，就是磁盘块。比如磁盘块为1024B，那一个文件2000B，它就必须申请两个磁盘块。所以一般来说磁盘块包含若干个扇区，也可以理解为操作系统把若干个扇区绑在一起作为一个磁盘块
- 页是在内存中占据空间的最小单位，一般大小是若干个磁盘块。
  - 页是进程中的概念，块（帧）则是页在物理内存中大小，实际上二者指向的东西是一致的，而页越大，页表就越小，所占内存就越少，查询速度就越高，而页对应块，则页越大，把块调入内存需要的 IO次数就越少，速度也会相对提高
  - 下面内存和cache交换的单位也称为块，不知道是不是我写错了

- 段是迎合人的理解而提出的一个单位，即一个函数的存储应该连续，所以被称为一段
- 块是内存和cache交换数据的单位，也叫行

那我们为什么要提出这么多单位的概念呢？因为按字节来找，来记录，自己想想都知道要耗费多少资源了。一块一块地拿，也能很好地防止浪费，一块没用完也不浪费多少（你要是按一字节一字节地拿，指针跳转的存储都是你文件的数倍了，肯定得按块去拿）

---

## 计算机的启动过程

计算机的启动是分阶段的

首先是初始引导，这个过程主要由BIOS(basic IO system)完成的，BIOS是固化在ROM里的，主要功能是内核和运行环境的检测，检测BIOS，内存，IO接口等，没有问题就会引导计算机到磁盘的0，1扇区去执行操作系统，把内核装进内存，再把命令解释器装进内存

计算机的部件配置记录是放在一片可读写的芯片，叫CMOS RAM，里面存着系统的基本情况，CPU特性，软硬盘驱动器，显示器，键盘等部件的信息（所以我们电脑关机后再开机，时间不会出错就在这个部件），但RAM是要通电的，所以我们要一块后备电池来供电

然后BIOS的ROM芯片有系统设置程序，用来设置CMOS RAM的各项参数

## 操作系统的分类

### 批处理系统

常见的批处理操作系统有DOS，当然现在各个系统也有.bat或.cmd文件，这个就是批处理文件

由于人机矛盾和CPU和I/O设备之间速度的矛盾，出现了批处理系统。这个想法很简单，我运行时不交互，那么以上问题都不会出现，我运行完了或者程序阻塞发出I/O请求，那么你要干啥随你

然后又分为单道批处理系统，多道批处理系统

#### 单道批处理系统

即内存只有一道程序在运行，并且是顺序调度，当然这样资源利用率和系统吞吐量都不行

#### 多道批处理系统

允许多个程序进入内存，并且在CPU交替运行，当一个程序因为I/O暂停时，CPU就去执行另一个程序

当内存里的程序数到达上限了，那就不能调外存的作业到内存里，只能眼巴巴地看着里面的程序运行完有位置了，才能用对应调度算法调进去。当然内存里还有内存调度

#### 批处理的问题

这个问题主要是程序运行时，不发起I/O请求，用户是无法和程序进行交互的，最简单的就是不能中断，程序运行时为了速度也不能故意降下速度去输出当前状态（毕竟批处理就是为了避免I/O才出现的，你频繁地输出，那自然和这个观念背道而驰）。这样不能人机交互，用户也不能了解程序运行状态，也不能控制计算机，用户响应时间也比较长

当然各种分配调度问题都没有去解决

### 分时操作系统

为了解决前面批处理操作系统的问题，所以提出了分时操作系统

分时技术就是把处理器运行时间分成很短的时间片，各个作业联合使用，如果一个作业不能在时间片内完成计算，那么就会暂停该作业，交给其他作业运行

这样就能实现人机交互了，用户响应时间基本感受不到

但对于一些对时间要求很高的场合，比如导弹制导系统，其需要的反应时间比时间片还短，这样分时操作系统就不能解决了，因此实时操作系统应运而生

### 实时操作系统

简单来说就是有时间限制的紧急任务不需要时间片排队。这里的时间限制分为两种：一种是不能超过时间限制的硬实时系统，一种是偶尔超过时间限制，且不会发生永久性损害的软实时系统

### 网络操作系统和分布式计算机系统

网络操作系统就是用网络通信，将各个计算机的资源共享和通信

分布式计算机系统和网络操作系统不同的地方在于，分布式操作系统的各个计算机协同完成同一任务

### 个人计算机操作系统

目前使用最广泛的操作系统，常见的有windows, Linux, Macintoch

### 嵌入式操作系统

这个没讲

### 操作系统的发展历程总结

![image-20220915122445855](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220915122445855.png)

# 第二章——进程管理

进程的概念在前面已经讲过一遍了，在这里就不再重复了

所以我们就讲一下进程的具体的实现的一些东西吧

## 进程相关概念

### PCB

进程实质上就是运行中的程序，它在内存里占据了一部分的内存空间，所以我们需要有一个它的信息的数据结构，用于控制这个进程，于是这个数据结构便被称为进程控制块，PCB（process control block）。

在PCB中，一般包括如下信息：

1、 进程的状态：状态科包括新建态、就绪态、运行态、终止态、阻塞态。

2、 程序计数器：用于记录进程要执行的下一条指令的地址。

3、 CPU寄存器这些信息CPU寄存器包括累加器，索引寄存器，堆栈指针，通用寄存器和其他一些条件码信息寄存器。这些信息描述了程序执行的状态，与程序计数器一起保存，以便进程以后的正确执行。

4、 CPU调度信息：这类信息包括进程的优先级，调度队列的指针和其他调度参数，为操作系统管理进程并进行调度提供支持。

5、 内存管理信息：根据操作系统对内存的使用情况，记录下基址，界限寄存器，页表、段表等信息。

6、 记账信息：包括CPU时间，实际使用时间，时间界限，使用数据，记账数据，作业和进程数量等。

7、 I/O状态信息包括分配给进程的I/O设备表，打开的文件列表等。

![image-20220906232122846](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220906232122846.png)

### 进程映像

然后我们会把PCB放到进程开辟的内存空间的特定的地方，同时内存空间里还放了程序段，相关数据段，它两和PCB构成了进程映像，也被称为进程实体。

下两张图对代码段和数据段有了形象而具体的描述，看完后应该对进程映像有更好的理解

下面这张图是程序编译后得到的可执行文件的每个部分的名字，比如段头部表，这个就和页表差不多，还有.init，.text等等部分。ELF头到.rodata部分称为代码段（只读内存段，毕竟代码段确实只读）；.data和.bss组成数据段（读/写内存段）；再往后的部分不加载到内存，并不是进程映像的一部分

![image-20220905121654555](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220905121654555.png)

下图是进程映像的具体样子

头顶的内核内存应该就装有PCB，这个是只有在内核态才可见的内存，也可以认为内核才有这个地方的页表，而进程没有，所以对用户代码来说不可见（我也不懂这样说对不对，也可能是不可读不可写的）。用户栈和堆是起始分配好的空间，分别往下和往上增长，中间的是共享库的内存，我还没看共享库是什么。然后到下面就是刚刚上面说的代码段和数据段（我也不懂栈和堆是不是和数据段组成了相关数据段）

![image-20220905121532438](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220905121532438.png)

进程实体可以理解为进程在内存里存的整体，但进程实体的概念更强调内存空间的概念，像是写在纸上的要做的事，而进程强调的是运行的过程，像是我们正在做的事（虽然放在外存的程序本身已经够静态了，但进程实体本质上来说只是在程序的基础上加了一些东西，并没有运行中的这个概念），所以说进程是动态的，进程映像是静态的。

而我们控制进程就是依靠PCB去控制的，所以PCB唯一地标识进程，也是进程存在的唯一标志

## 进程的状态与转换

我们总不会希望我们的电脑一段时间内只能运行一个程序，这样太难受了，我们希望进程间能分时复用CPU就好了，那么进程就需要有几个状态，有些状态能用CPU，有些不行。这些状态信息都放到PCB中。那我们下面就介绍这些状态

注意，在讨论进程状态时，此时的时间是分配给用户进程，不用考虑操作系统用的时间。

而且时间片的时间到了并不会把执行到一半的一条语句打断，要么把执行完的那一半扔了，要么执行完后一半（这里的语句并不意味着原子语句，原子语句是不能打断的一个或多个动作，语句是一个动作，一个动作是不能被打断的，是必须做完的）

### 各种状态

- 创建态
  - 进程正在被创建的状态，主要是操作系统往PCB里写东西，分配进程空间的过程
- 阻塞态
  - 进程等待某些资源（如打印机正在被占用）而不去抢CPU的状态
- 就绪态
  - 等待CPU，在抢CPU的队列的状态
- 运行态
  - 抢到了CPU，在运行中的状态（这里说的运行就是用户程序的运行，而不是内核的运行，内核不是进程，所以CPU要么是进程占用，要么内核占用，要么空着）
- 结束态
  - 操作系统释放进程所占用的资源的状态

![image-20220904181453765](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220904181453765.png)

那这里又有一个问题，我们只有一个用户进程时，我们不能根据就绪态为空而不退出这个进程吗？非要调到就绪态再调回来吗？首先，只有一个用户进程的情况很少，所以我们加了一个判断在绝大多数的情况都浪费了，所以不值得。其次能用一个规则解决的，就不要用多个规则去解决

## 进程控制

下面讲创建进程，撤销进程，进程状态转换等功能，统称为进程控制

我们把操作系统中用于进程控制的程序称为原语，源于在执行期间不允许中断，是一个不可分割的基本单位（其实原语应该是指操作系统中最基本的程序和操作，由若干条指令组成的程序段，不能执行到一半被打断）

为了进行调度进程，所以我们内存还有就绪队列和等待队列

### 进程的创建（还有父子进程的详细讲解）

#### 父子进程的讲解

我们不仅允许操作系统创建进程，我们还允许一个进程创建另一个进程，此时创建者称为父进程，被创建者称为子进程。子进程继承父进程的所有资源数据，包括父进程的上下文，也就意味着子进程刚开始运行时，会和父进程执行的命令处于同一位置（所以父进程fork()后子进程也处于fork()的末尾，然后父进程的fork()返回1，子进程的fork()返回0？），子进程创建成功之后，和父进程同时执行，竞争系统资源，谁先执行由调度算法决定。

这里说一下子进程的意义，听起来子进程和线程的意义差不多，但子进程和线程最大的区别是进程是资源分配的基本单位，线程不是。这就意味着子进程修改的变量并不会修改父进程的变量，但线程修改的变量会修改父进程的变量。其次，资源分配不仅意味着内存空间的分配，还有时间的分配，操作系统分配时间的单位是进程，而不是线程，这就意味着线程变多并没有在实际意义上提高了程序占据CPU的时间，但多进程可以真正提高程序占据CPU的时间，从而实现提高程序运行的速度。当然，多进程的代价就是其他程序变慢了

然后我们来讲一下父进程和子进程的内存空间的使用。前面我们说了，进程是资源分配的基本单位，然后子进程是名义上的把父进程的资源全部继承，那么子进程会把父进程的进程实体全复制一遍吗？这样做实在有点浪费，我们只要复制需要复制的就好了。首先我们要知道的一点是，我们所有进程中看到的，使用的内存，都是虚拟内存，虚拟地址，所有的逻辑地址都需要通过页表去映射到内存的物理地址上。然后每个进程都有个页表，所以我们不用修改的数据，直接用页表，父子进程都映射到同一个物理地址的页即可，或者说是进程视角来看进程拥有的就是页表，页表会映射到物理地址，从而实现内存空间的分配。

那么代码段就不用复制，大伙都是按这玩意做的，我让页表指向同一个页就好；

但数据段，堆，栈的各页，BSS段，文件描述符，由于父子进程的数据是相互独立的，所以我们用上面说的写实复制的技术，即一开始大家的页表指向的都是同一个页帧，当一方改动以后，数据不同了，就新建一个页帧，改动者的页表指向那个页帧即可

注意，文件描述符并不是系统中真正联系到文件的结构，而是指向真正文件结构——内核文件表项，所以虽然我们父子进程的文件描述符占据的空间可能不同，但两个文件描述符指向的其实是一个内核文件表项，这就意味着父子进程本质上是共享一个文件

文件流缓冲区的资源位于用户空间，所以全部复制。即如果流缓冲区中有临时信息，都会复制到子进程的用户空间流缓冲区中。

然后PCB里的绝大部分数据都会复制，当然每个进程都有自己的标号，这个不会复制

总结一下就是子进程会复制父进程的几乎所有信息：子进程复制父进程用户空间所有数据；子进程复制父进程内核空间PCB中绝大多数数据；用户空间即非内核空间的空间；使用写实复制技术，改动后才使用新的空间，复制改动

然后说一下进程的结束，我们一般用exit()结束进程，但运行时发生致命错误或收到终止信号都会结束进程的。在子进程结束后，操作系统会用SIGCHLD信号发给父进程，父进程会使用wait，然后内核就可以从内存释放子进程的PCB。但如果父进程没有这么做（不这样做内核就不知道父进程收到了SIGCHLD信号），那么子进程的PCB就会留在了内存了，成为了僵尸进程（就是死了但尸体还占着地方）。而孤儿进程就是父进程结束了，但子进程还在执行，那么子进程就变成了孤儿进程（就是没了爸爸但还活着）。在类似UNIX系统中，孤儿进程一般会被init收养，成为init的子进程，从而进行管理和回收

#### 创建进程的过程

1. 分配唯一的进程识别号，并分配空白的PCB，注意，PCB是有限的。若分配失败，则进程创建失败
2. 分配资源，如内存空间。注意，分配失败不意味着进程创建失败，进程会进入阻塞态，等待内存空间的释放
3. 初始化PCB，比如标志信息，控制信息，进程优先级的初始化
4. 如果进程就绪队列可以接纳新进程，则进入就绪态

### 进程的终止

1. 根据被终止的进程的标识符，找到对应的PCB，从PCB里读出该进程的状态
2. 若处于执行状态，则终止该进程的执行，CPU的资源分配给其他进程
3. 若还有子孙进程，终止其所有子孙进程
4. 将占有的资源归还给父进程或操作系统（我对归还给父进程的理解是子进程虽然是从公共的内存空间申请来的空间，但是以父进程的名义去申请的，所以是归还给父进程，而归还给操作系统是把PCB的空间还回去）
5. 将对应PCB从就绪队列里删除（就绪队列里放的是PCB的标号吗？前面都释放了PCB的空间了）

### 进程的阻塞和唤醒

在请求资源失败，等待操作完成，无事可干的时候，系统会自动调用原语block()，变成阻塞态

注意，王道里讲“阻塞是程序的主动行为，所以只有处于运行态的进程才会进入阻塞态”这句话有问题，上面刚讲了进程创建时申请不到内存会进入阻塞态，但很明显这时进程处于新建态。我对“阻塞时程序的主动行为”这句话都有所怀疑，因为上面自己说“系统会自动调用原语”，这两句简直是自我矛盾

#### 阻塞原语的执行过程

1. 根据标识号找到PCB
2. 若进程处于运行态，保护现场。将其转换成阻塞态，停止运行
3. 将PCB插入等待队列

#### 唤醒原语（wakeup）执行过程

唤醒的时机举个例子，I/O处理完成，就会给CPU发出一个I/O中断，那CPU先把手头的工作先放下，先处理I/O的事，这时候就唤醒了，把等待态转化为就绪态

1. 找到等待队列里的PCB
2. 移出等待队列，转换成就绪态
3. PCB插入就绪队列（有个问题是队列装不下了会把就绪态变回去吗？）

### 进程的切换

1. 保存处理机上下文，包括程序计数器和其他寄存器
2. 更新PCB信息
3. 把PCB移入相应队列
4. 选择另一进程，更新其PCB
5. 更新内存管理的数据结构，主要是页表的快表TLB的更新
6. 恢复对应进程的上下文

切换和调度还是有很明显的区别，先调度，再切换，调度是选择哪个进程占用CPU，切换是选中哪个进程占用后执行的切换操作

## Linux下的几种创建进程的方法

Linux有几种创建进程的方法：fork()，vfork()，clone()

### fork()

fork()就是我们上面所说的函数，采用的是写时复制，返回值对于父进程是子进程的pid，对于子进程是0

### vfork()

vfork()使用的是共享内存技术，即子进程使用的内存空间就是父进程的，子进程修改了一个变量，父进程也会看到修改。另外父进程会被一直阻塞，直到子进程调用exec（exec就是把一个新的可执行文件调到地址空间里并执行）或调用exit后，父进程才会解除阻塞，才可能给OS调度。所以用vfork()必须要用exit表示子进程结束，不然父进程会一直阻塞，但fork()就没这个问题。虽然我现在都不知道vfork()有个鸡巴用，说是为了调用exec函数执行另外的程序

### clone()

clone()就是有选择地复制父进程的资源给子进程，而没有选择的资源，则可以通过共享内存技术，用指针的复制给子进程共享。clone()算是前两者的融合。前两者都没有参数，而clone()有参数，这些参数是用来选择复制的数据的，比如CLONE_VM,CLONE_FILES标志使得变量和文件描述符表被共享，而CLONE_VFORK标志可以让子进程运行时父进程阻塞

## wait()和waitpid()详解

wait()一般和fork()配对使用

wait()的作用是阻塞父进程，并寻找父进程中的僵尸进程（子进程退出后会把除PCB外的资源释放，只留下一个PCB给父进程反馈信息，所以就像僵尸一样死了还留在那里），找到一个就会释放这个僵尸进程的资源，并返回其pid。注意，wait()是找僵尸进程，所以并没有保证找的是哪个僵尸进程，所以释放的进程不一定是你想要的，释放的顺序也不能保证，而且一次只能释放一个

所以我们有了waitpid()函数，它可以指定pid，就等着这个子进程结束

## 进程通信

进程通信就是进程间的通信，低级通信就是利用操作系统的原语P，V（这个应该在后面的进程同步互斥会讲到）进行交换信息，但传送的信息量小，传送的类型只能整数和状态，还要用户直接实现通信细节，容易出错。低级通信主要用于进程同步，互斥，终止，挂起等信息同步

所以我们提出了高级通信，能传输大量数据，有三种

### 共享存储

通信的进程间弄一块大家都可直接访问的共享空间，对该空间进行读写时，需要使用同步互斥的原语P，V去进行控制。

低级方式实现的共享基于数据结构，高级方式实现的共享基于存储区

注意，进程一般只能访问自己的内存空间，所以我们要弄一块能共享的空间，就需要特殊的系统调用来实现

### 消息传递

这个就是操作系统提供发送和接收信息的原语，然后两个进程都有发送缓冲区和接收缓冲区就行了。这样比起共享存储的方法就不需要对共享地址空间进行通信和同步的限定，对于连接网络连接的不同计算机，这样就能省很多事了（其实我们计网课设里的套接字的send()，receive()就是这样子的）。和低级通信的区别可能就是新的原语和缓冲区吧

所以共享内存主要用于在不通过网络的情况下，一台机器内部（单处理器的机器或多处理器的机器都行）的数据通信

而消息传递主要是网络通信，主要用于分布式系统。因为每次传递都是用系统调用，不像共享内存系统调用一次建立好内存就行，所以相对于共享内存慢

分为两种通信方式

#### 直接通信方式

就是你要发给谁，就发给谁，会自动放到对方的缓冲区里

#### 间接通信方式

就是你发给一个中介，一个中间实体，比如一家公司的电子邮件系统，它帮你存着，然后接收方从这个电子邮件系统去取。和共享内存的区别就是消息传递是分布式系统，是网络通信，而不是一个机器的内部通信

### 管道通信

共享存储方式不是要有一块共享内存，很麻烦吗？那咱们就不搞一块内存，搞外存，这样就不需要系统调用分配内存了

我们用一个文件，称为pipe文件，又称共享文件，又称为管道，本质上可以理解为两个进程间消息传递的缓冲区（其实所有通信都是以缓冲区的方式解决的）。我们两个进程就通过这个文件进行信息交换，当然一个文件只能实现单向的通信，所以要双向就得两个文件，所以管道通信必然是半双工通信（半双工的定义感觉怪怪的）。

当然为了协调双方通信，我们还需要有三种能力：互斥，同步，确定对方的存在（这个在后面的生产者消费者应该会讲到）。

当然，管道文件和一般的文件还是有些地方不一样的，毕竟这是个用来通信的缓冲区，而不是真正的文件。有以下两点区别

- 管道的大小是被限制的。缓冲区肯定不能无限大，缓冲到一定程度就让write()被阻塞到read()读后腾出空间就好了
- 管道空了，那么read()就要被阻塞，直到有东西被write()

## 进程和操作系统通信方式

- 寄存器
- 堆栈
- 共享内存

## 线程概念和多线程模型

### 线程概念

引入进程的概念是为了多道程序并行，而引入线程的目的是减小程序在并发执行时付出的时空开销，提高操作系统的并发性能（多线程的本质是有些任务是可以独立进行，但在单线程时程序会处于等待状态，比如数据库访问，磁盘IO之类很慢的，使得CPU啥都不干，这样就很浪费了）

线程使用的是进程的资源，线程也可以创建线程，这样线程之间也互相制约了，所以线程也有就绪，阻塞，运行三种基本状态

进程切换需要对资源进行分配和回收资源，保护现场和新进程的现场设置，所以比较慢，但线程切换只要在分配好的资源里保存设置少量寄存器，而且进程里的地址是一致的，所以无需操作系统干预就能同步和通讯，这样就不像进程那么麻烦

### 线程的实现

线程的实现分两类：用户级线程(User-Level Thread, ULT)，内核级线程(Kernel-Level Thread, KLT)

用户级线程就是有关线程的管理（线程的创建，撤销，切换）由应用程序完成，和内核无关，内核也意识不到线程的存在，应用程序通过线程库管理线程

内核级线程就是线程管理的工作由内核完成（上下文信息也是内核维护），应用程序没有线程管理的代码，只有一个到内核级线程的编程接

还有些系统搞了个组合线程实现，应用程序通过线程库映射到内核级线程中。假设用户级进程有n个，通过线程库我可以把这n个线程映射到m个内核级进程中，而m<=n

三者的实现如下图

![image-20220914193110089](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220914193110089.png)

有些系统还可以内核进程和用户进程都支持，所以可以用户进程和内核进程的多对一，一对一，多对多的连接方式

## Linux下的线程创建函数：Pthread()

```c
#include <pthread.h>//pthread头文件
#inclued <stdio.h>

struct ManyArg{
    int arg0;
    char arg1;
};

void foo(void * arg1);//子线程要运行的函数，函数名本身可以看作一个指针

int main(){
    pthread_t tid;//线程的标识符
    pthread_attr_t attr;//记录线程状态的结构体
    
    struct ManyArg manyArg;
    manyArg.arg0=1;
    manyArg.arg1='k';
    
    pthread_attr_init(&attr);//初始化线程状态结构体
    pthread_create(&tid,&attr,foo,（void*)&manyArg);//创建线程，创建后线程便执行.但你创建多个，线程之间的执行顺序不一定是你创建的顺序，但似乎又有所关系，目前还不清楚.第三个参数是执行的函数，第四个参数是传入该函数的指针,但只能传一个指针，并且必须要是(void*)类型的，真的很傻逼
    pthread_join(tid,NULL);//等待指定对应tid的线程执行完成，解除阻塞
    return 0;
}

void foo(void *arg1){
    struct ManyArg manyArg=(struct ManyArg*)arg1;
    printf("%d %c",manyArg->arg0,manyArg->arg1);
}
```



## 处理机调度

这里讲的是总的调度，进程调度是其中一种

做一件事情，或者说一个作业，从硬盘到执行，要经过以下三级调度

### 作业调度（高级调度）

- 从外存请求载入内存的作业（程序）选一个或多个载入内存，给它们分配内存，输入/输出设备等资源。所以作业调度就是从外存到内存的调度

### 内存调度（中级调度）（早期的垃圾设计）

- 这个就是在内存不够用的时候，把不能运行的进程（处于就绪态或者阻塞态）调到外存去等待，然后此时的进程处于挂起态（进程的状态不一定严格遵守前面我们说的那几个状态）。
- 挂起态和阻塞态不一样，虽然二者都不占用CPU，但挂起态调出了内存，而阻塞态还在内存。然后挂起态是OS或者用户发起的，要由它们恢复，而阻塞态是资源不够或者进程执行触发的，等资源够了或者进程本身限制的条件解除时，就会解除阻塞，进入就绪态，排就绪队列

### 进程调度（低级调度）

- 从就绪队列里选一个进程分配处理机，选的方案就是调度的策略。进程调度是操作系统最基本的一种调度，一般的操作系统都必须配置进程调度

![image-20220916133754128](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220916133754128.png)

## 调度的时机，切换，过程

进行调度，然后切换到得到调度的进程，一般来说二者是连续执行的，但在某些情况下，我们不一定能连续执行二者

### 不能调度和切换的情况

不能调度和切换的过程如下

- 中断过程，中断逻辑上属于系统，不属于进程，那么此时就不能中断
- 进程在操作系统内核程序临界区中（是说进程需要使用内核提供的服务而从用户态进入内核态，而此时的操作又有需要上锁的部分，也就是说有临界区，而此时刚好处于临界区吗？）。此时因为加锁的缘故，其他进程是不能抢的，所以在解锁前不应切换到其他进程，以便加快解锁
- 各种原子操作，这些原语不能被打断，所以调度，中断等都不能进行

## 进程调度方式

有两种调度方式，非剥夺调度方式，剥夺调度方式

### 非剥夺调度方式

就是即使有更紧迫的进程在就绪队列，也要等到当前进程完成或阻塞为止才能抢（这里没有时间片的概念，本质上就是批处理系统的产物）

这个方式比较适合批处理系统，实现简单，系统开销小

但不能用于分时系统和大多数实时系统

### 剥夺调度方式

就是有更紧迫的进程在就绪队列里，就立刻暂停当前进程，CPU分配给这个更紧迫的进程（时间片的剥夺也是剥夺）（倒不如说非剥夺方式就是非要做完或阻塞才能给别的进程，而剥夺就是与之相反，不一定要做完或阻塞才能抢）

又称为抢先式调度

这个方式能提高系统吞吐率，响应效率

但不能随意剥夺，主要遵循以下原则

- 优先权
- 短进程优先
- 时间片原则

## 调度的评价准则

### CPU利用率

- 指CPU运行用户进程的占比
- 所以操作系统的占比没有算进去
- 比如100 min中，用户进程占30 min，操作系统40 min，空转30 min，那么CPU占用率30%
- 所以操作系统复杂，CPU利用率就会降低，简单的话，功能又不够强大

### 系统吞吐量

- 即单位时间内CPU完成的作业量，所以长作业耗时较长，所以我们要考虑怎么让短作业更多地占用CPU

### 周转时间

- 即作业从提交到完成所需要的时间（包括作业等待，在就绪队列中排队，在处理机上处理，输入/输出操作所环肥的时间综合）

### 平均周转时间

- 就是所有作业花费的时间的平均

### 带权周转时间

- 就是周转时间和真正在CPU里运行的时间的比值（说真的，“带权周转时间”这个名字真的很容易让人误解，应该叫“真正运行时间占比”）

### 平均带权周转时间

- 就是多个作业的带权周转时间的平均

### 等待时间

- 就是非占用处理机的时间，所以就是周转时间减占用处理机的时间

### 响应时间

- 作业提交请求到系统首次响应所用的时间，主要是评价交互式系统的响应速度的
- 当然响应时间短就意味着需要不断换进程去响应，换进程的话，等待时间就会增加

## 典型的调度算法

### 先来先服务（FCFS）算法

字面意思，先来先到，就绪队列里排着，可用于作业调度，进程调度

属于不可剥夺算法

看起来是公平的，但长作业就能占用更久

所以只是用来辅助其他算法，并不用作主要调度算法

### 短作业优先（SJF，short  job  first）调度算法

可用于作业调度，也可用于进程调度，从后备队列里挑一个估计运行时间最短的作业（进程），调到内存运行（分配处理机给它），直到执行完成或阻塞时（这里没有时间片的概念）才释放处理机

实际上就是FCFS的升级版，FCFS的等待时间太随机了

短作业优先有剥夺和非剥夺的两种版本，剥夺的就是根据最短的剩余处理时间，优先剥夺。剥夺短作业优先在忽略上下文切换时间的情况下，平均等待时间更短。

当然预测短作业运行时间是根据上一次的执行时间 t 和这一次预测的时间 T做一个加权 a 相加得到下一次预测的时间 T ，即

> T=a t + (1-a) T



从这里就可以看出短作业优先本质就是一种优先级调度

考试没有强调是否剥夺就把两种情况写上

缺点就是

- 长作业不利，会出现饥饿现象（饥饿是调度问题，死锁是资源得不到，环形等待问题）
- 紧迫的作业也不能优先处理
- 另外这样用户会有意缩短作业估计的运行时间，这样不一定真正短作业优先

当然，SJF在平均等待时间，平均周转时间方面最少（毕竟短作业优先，做的作业自然就多，平均下来自然就消耗时间最少）

### 优先级调度算法

可用于作业调度，进程调度。用优先权来描述作业的紧迫程度

在作业调度中的实现：

- 从后备队列里选优先级最高的一个或几个，分配资源，调到内存，放入就绪队列

进程调度的实现：

- 从就绪队列选优先级最高的进程分配处理机

优先级调度算法还可以分为非剥夺和剥夺两种情况

- 非剥夺：就绪队列里有优先级更高的进程仍旧让当前进程执行
- 剥夺：就绪队列里有优先级更高的进程，就立刻暂停当前进程，分配处理机给优先级更高的进程

当然还可以根据进程优先级分为两种

- 静态优先级：即创建进程时确定的，运行时优先级也不改变，这样容易饥饿
- 动态优先级：运行时根据进程状态调整优先级，比如根据你等待的时间调高你的优先级。当然CPU利用率就下降了，因为需要不断维护动态优先级

然后下面介绍一般的优先级高低

- 系统进程>用户进程
- 交互型进程>非交互型进程，或者前台进程>后台进程，主要为了用户响应更快
- I/O进程>计算型进程，I/O进程尽早开始，这样就可以减少等I/O的时间了

### 高响应比优先调度算法

主要用于作业调度

记响应比为

$$响应比=\frac{等待时间+要求服务时间}{要求服务时间}$$

每次进行作业调度时，挑响应比最大的作业进入内存

这个算法非常巧妙，短作业自然有很大的优势，但长作业等待久了，响应比也相应增大，这样长作业也不会饥饿

### 时间片轮转调度算法(RR)

到这里为止，调度算法才提出了时间片的概念，前面的算法时没有时间片的概念的（所以前面很多都是非剥夺）

就绪队列先来先到，每个时间片选就绪队列里的第一个进行分配，时间片到了就选就绪队列里的第一个进行分配。在时间片截止前做完了就提前切换

所以这个调度算法性能很依赖时间片的大小，小了频繁切换，开销增大，大了就和先来先到每区别了

唯一的好处就是响应时间快

### 多级反馈队列调度算法

这个算法融合了前几种算法的优点

运行思想如下

- 有多个就绪队列，每个队列都有优先级，第一个队列优先级最高，第二个队列优先级次之，其余队列优先级递减
- 每个队列的拥有的时间片大小不同。第 i 队列的时间片长度是第 i - 1 队列的时间片长度的两倍
- 当一个新进程进入内存后，放到第一队列的队尾。如果在一个时间片里没做完，就要放到低一级队列的队尾。到最后一个队列时，就正常地时间片轮转就好了
- 分配规则是分配给有进程的最高优先级的就绪队列的第一个进程，所以后面优先级的进程必须等前面队列全空了才能得到分配

可以看出这个方法的优点

- 短作业优先，长作业不饥饿
- 周转时间较短
- 也不用估计进程的执行时间

当然这个算法的进程优先级没有考虑

一般用于小型机（大型机>小型机(服务器)>微型机(一般人用的电脑) ）

## 进程同步

进程同步的意思是多个进程之间应该处于一个正确执行的顺序，那么多个进程之间就实现了相对同步了（你想做快一点就会被别的进程卡住），所以称为进程同步了

这里说一个前提，我们下面说的软件实现并不是我们编程的语言的实现，下面所写的语言也只是为了方便人理解而写的，并不是真正的实现。我们下面所说的进程同步只是操作系统里为了解决资源抢占（这里的资源既指硬件资源，也指操作系统内的某些数据）的问题，而并非我们程序设计中的进程同步问题

## 进程同步的基本概念

### 临界资源

就是一次只能给一个进程访问的资源

我们提供了两种实现方案：软件实现，硬件实现。注意，实现不代表操作系统实现，也可能是用户程序实现，这里只提供一种方案，并没有要求必须操作系统来做

还有一点要注意，我们下面所给的代码只是为了说明执行过程，不代表真实代码

（但一个代码语句就是原子语句？）

#### 临界区

我们写程序的时候，要访问临界资源，那么肯定会写访问临界资源的代码，那么我们把访问临界区资源的代码段叫做临界区（注意，这里不是操作系统里的代码，纯纯的用户程序手写的实现）

临界区这个概念在进程和线程中都有，这里只讲进程的临界区

另外临界区对象这个概念是线程的

那我们想要达到临界资源一次只有一个进程访问的结果，那么我们就要弄一个或多个共享变量（用共享内存或者其他技术，实现不同进程能访问的同一个变量），用共享变量来告诉每个访问这个临界资源的进程，当前是否有进程在访问（这里就有个很大的问题，我要是不管你的共享变量，我直接访问临界资源，那谁也管不了我，出问题了我也不关心，我就想搞破坏，那我是一点办法也没有，当然这只是我的猜想，至于有没有防范措施我还不清楚）

然后我们程序访问临界资源的代码就可以分为4个部分

- 进入区
  - 检查共享变量，看看这个进程能否进入临界区，并要对共享变量进行一定的操作，让自己进了临界区的时候防止别人进临界区
- 临界区
  - 访问临界资源的代码，也叫临界段
- 退出区
  - 对共享变量进行一定的操作，让别的进程能进临界区
- 剩余区
  - 代码的剩余部分，我也不知道这是个什么东西，好像也没人关心它是什么东西

四个区如图（仅示意）

![image-20220917180854685](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220917180854685.png)

### 同步

这个就和上面说的一样，因为某些制约关系，做得快的进程也会被卡住，等特定进程把任务做完了才能继续运行，这样进程间看起来就同步了。所以同步亦称直接制约关系

### 互斥

一个进程使用临界资源，另一个进程必须等待，这就叫互斥。互斥也称间接制约关系

## 实现临界区互斥的基本方法

有软件实现和硬件实现，当然信号量应该也能实现，但信号量还能进行同步，所以放到后面来讲

软件实现和硬件实现的区别是，软件实现真的就是全软件，硬件实现就是程序使用一条能直接用硬件实现的指令。

然后软件实现和硬件实现都是在用户程序的访问临界区的代码段，加代码去实现。

### 软件实现

就是进入区本身是个循环，在进入区检查一些共享变量，只有临界区可以进入了才能跳出循环，往下执行临界区（这里和上面的示意在外面套while不同，这里是在进入区套while，其他地方不套）

软件实现是早期的设计了，所以会比较烂

然后我们下面讲以下软件实现的各种算法和各自的优缺点

#### 单标志法

共享变量 turn，表示当前被允许使用临界区的进程编号，比如 turn = 10，则表示当前允许10号进程进入临界区，然后标志轮流变

![image-20220920095738541](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220920095738541.png)

那这有个很明显的问题，比如当前 turn=1，但进程1一直不用，那么别的进程也占用不了

#### 双标志法先检查

就是用一个共享数组，数组的第n个元素表示对应进程是否进入临界区，这样我们看看没进程用了那就进入临界区就好了

![image-20220920100414330](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220920100414330.png)

那这又有问题了，如果我们的进程按上图的1，2，3，4的顺序执行语句，那么我们还没来得及改我们的标志位，别的进程就检测了，那两个进程肯定会一起进入临界区

#### 双标志法后检查

那前面的方法改得太慢了，那我先改标志位，再检查，这样你就不可能和我同时进临界区了

![image-20220920100911071](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220920100911071.png)

那这还是有问题，假如还是之前1，2，3，4的顺序执行语句，那两个进程都改了自己的标志位，然后检查，那两个进程就饥饿（不知道能不能说是死锁，因为死锁是循环等待资源，而这里是调度）了

#### Peterson算法

那第三个算法的问题在哪？因为二者的结果不能覆盖。那第一个算法能覆盖了，为什么也有问题？因为进程执行完后没有一个方式表示释放了该资源

那我们把两个方法结合一下不就好了吗？用 turn 来表示当前占用资源的进程（注意，这里只能实现两个进程的临界区），flag[] 表示某个进程是否占用资源。当二者同时抢，那 turn 肯定有一个进程最后改，然后到算法最迷惑的地方了，它是让被改的进程去执行（虽然也可能是为了先来先到吧），资源释放后，另一个进程执行

![image-20220920110600995](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220920110600995.png)

#### 个人想法和实现

如果要实现覆盖的话，turn 在多个进程抢的时候算法就做不出来了。我个人的看法是，要实现覆盖和表示占用资源，那我大可以用一个队列，先来先到，队列头不是自己就不进入临界区，在进入区循环等着，自己做完退出时把队列头弹出就好了。再烂一点，我连先来先到都不想实现了，直接一个数组，序号在前的表示占有资源的进程能进入临界区，其他不能，做之前把占有标志改了，别的进程不能进行其他进程的检测，做完了就把占有标志改回来，又能进行进程检测进入临界区了，这不就完事了吗

### 硬件实现

这里就是直接在访问临界资源相关的代码段调用一些能用硬件直接实现的指令，我们称硬件实现的方法为低级方法，或元方法

下面我们讲一下各种方法

#### 中断屏蔽方法

直接用指令把中断关闭了（作用类似于计组课设里的中断的 EI, DI），如图

![image-20220923130449832](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220923130449832.png)

当然这样看起来就很危险，毕竟把中断的大权给了用户，不能中断了，那时间片都没法中断了，如果进程没有再次开中断，那系统就完蛋了

#### 硬件指令方法

前面我们不是用软件实现了修改标志吗？但是由于修改标志，检查标志需要多个语句，也就是多个动作，会被打断，所以我们费尽心机去解决这些问题，太麻烦了

那如果我们能让修改标志，检查标志变成原子语句，这样就不用那么麻烦地搞来搞去了

所以有了 TestAndSet 指令

**TestAndSet** 指令

指令执行的动作集示意如下

![image-20220923140139417](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220923140139417.png)

使用示例如下

![image-20220923140515289](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220923140515289.png)

这样第一句

```c
while TestAndSet(&lock);
```

就成一个原子语句了，修改和检查不能被打断分割。如果lock已经被人设置为true了，那么就会一直循环，如果lock被人释放了，while抢到了的话就会锁上，并且退出循环

当然还有别的硬件指令

**Swap** 指令

执行示意如下

![image-20220923143121755](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220923143121755.png)

使用示例如下

![image-20220923143157421](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220923143157421.png)

![image-20220923143205092](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220923143205092.png)





这里我们就可以看到硬件实现的优点，不会像软件实现那样只能实现两个进程的同步。硬件实现任意数目的进程，任意数目的临界区都可以实现。代码也简单

缺点就是要占用处理机的时间，且不能实现优先级，可能会饥饿

## 信号量

这个就是把硬件实现的想法挪用到软件实现上来，软件实现不是没有原语吗，那我们提供原语，但这些原语是软件实现而不是硬件实现，那不就行了嘛？

软件实现原语也很简单，你这个原语开头关中断，最后开中断就好了嘛。实际上就是把开关中断打包进函数了，这样你就不能乱用开关中断了

然后这个函数干的事情就是我们在进入区，退出区的事情，就是把修改检查操作变成软件实现的原语

然后占用标志就叫信号量S，能检查S的原语叫wait(S)，也叫P操作；能修改S的原语叫signal(S)，也叫V操作（检查就是检查是否有人用，没人用就占用资源；修改就是用完后资源释放）

P意思是通过，V意思是释放，两个都是荷兰语，所以别管了

信号量不仅能用于临界区互斥，还能用来各种同步互斥

下面介绍两种信号量和对应的PV操作

### 整型信号量

信号量S就是一个整数

wait(S)和signal(S)执行如下

![image-20220927125753852](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220927125753852.png)

整型信号量就完成了资源“忙等”（即不放弃占用CPU，只是不进入临界区，很浪费），但没有实现“让权等待”（即放弃占用CPU，这样就不浪费）

### 记录型信号量

前面我们不是一直用while作为防止程序进入临界区的手段吗？但while只能实现“忙等”，如果我们能实现阻塞，即调用阻塞原语，让程序进入等待态，这样就能实现“让权等待”了

那我们这样设计，S是一个struct，里面有占用资源的计数和等待的进程的队列，然后wait(S)时，如果被占了，那就把进程加到信号量的队列里，并且阻塞该进程；然后signal(S)释放资源时，就解除队列头的进程的阻塞，这样就近乎完美了

![image-20220927131525937](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220927131525937.png)

![image-20220927131039581](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220927131039581.png)

![image-20220927131055290](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220927131055290.png)

![image-20220927131134985](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220927131134985.png)

### 用信号量实现同步

同步就是一个进程要等等别的进程

下面举个实现例子

![image-20220927132001825](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220927132001825.png)

我们初始化S=0，这就导致P2必须等P1执行完后执行V(S)后才有资源，才能用P(S)解除自己的阻塞

### 用信号量实现互斥

可用于临界区，也能用在各种需要互斥的地方

![image-20220927132250341](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220927132250341.png)

就是在互斥的地方加锁，做完解锁。当然初始化S=1，不然没有资源了

### 用信号量实现前驱关系（比较复杂的同步）

就是某程序的执行必须等到别的某些程序执行完才能解除阻塞，就在同步的基础上加多几个信号量就好了

举个例子

![image-20220927132851909](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220927132851909.png)

![image-20220927132908333](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220927132908333.png)

![image-20220927132918971](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220927132918971.png)

### 信号量不会死锁的情况

两个进程使用信号量的顺序一致时，不会出现死锁，不一致就可能出现死锁

## 管程

到处都在用信号量，那就很容易写错然后死锁了，所以我们提出了管程，即一个资源，我们给它封装起来，它对外提供少量信息和对这个资源的操作，这样互斥什么，管程内部自己实现就好了（或许这就是封装的意义）（所以管程的概念就很像类，当然类这个概念并没有共享内存）

### 管程的组成

- 管程的名字（类名）
- 局部于管程内部的共享结构数据说明（数据结构的声明/定义？）
- 对该数据结构的操作（函数）
- 对局部于管程内部的共享数据设hi初始值的语句（数据初始化）

如图

![image-20220927134746875](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220927134746875.png)

### 条件变量

这玩意算是进程内的信号量的实现吧

条件变量就是

```c
condition x
```

条件变量可以理解为一个类condition，condition提供两个方法，wait()和signal()

```c
x.wait();//阻塞这里

x.signal()//解除x的wait()的阻塞
```

和信号量的区别其实还是挺大的

condition只是一个类，下面有wait()和signal()两个加锁解锁的操作；而信号量本身是一个数据，配套了PV操作，还是要靠信号量是否为零来控制阻塞的。当然二者的作用差不多就是了

## 经典同步问题

我们总有各种各样的进程同步，下面就介绍一些经典的同步问题

### 生产消费者问题

简单来说就是多个进程共享一个缓冲区，有些进程往缓冲区里写，有些进程从缓冲区拿。并且缓冲区是临界资源，同一时间只能读或写。缓冲区有东西才能拿，没有满才能写。读的进程称为消费者，写的进程称为生产者

那我们就用信号量来解决这个问题（软件实现太烂了）

弄三个信号量，一个信号量叫empty，表示缓冲区还有多少空间，一个信号量叫full，表示缓冲区已经填了多少数据，一个信号量叫mutex，表示当前临界区是否有进程在占用，

> 记住P是把信号量减一，V是把信号量加一。信号量被P减到0时，会阻塞；信号量被V加到大于0时，会解除信号量里的阻塞队列的第一个进程

P(empty)就是看看还有空间吗，P(full)就是看看有没有东西，V(empty)就是表示我释放一个空间，V(full)表示我占用一个空间（这里就把信号量灵活运用了）

P(mutex)和V(mutex)就纯纯的加锁

如图

![image-20220930141355920](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220930141355920.png)

### 较为复杂的生产者消费者问题

#### 1.水果问题（不同消费者拿不同产品问题）

- 盘子能放水果。一次只能放/拿一个，只有盘子为空的时候，才能放
- 爸爸只能放苹果，妈妈只能放橘子
- 儿子只能拿橘子，女儿只能拿苹果

还是那样用信号量

plate表示盘里是否有东西，apple表示盘里苹果数量，orange表示盘里橘子个数

P(plate)就是往盘子放东西，V(plate)就是从盘子拿东西

P(apple)就是从盘子里拿苹果，V(apple)就是往盘子里放了苹果，orange同理

![image-20220930142714426](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220930142714426.png)

![image-20220930142728685](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220930142728685.png)

#### 2.读者写者问题（部分进程不互斥问题）

- 一个共享文件，有读进程，写进程
- 可以同时读出（也就是说别的进程在读的时候，你也可以读，不会被阻塞）
- 只允许一个写，且此时不允许读

记rw为写信号量，w为

那实际上就只要在写进程和第一个读进程（防止别的读进程也调用P(rw)导致被阻塞，这样就不符合题意了）P(rw)一下阻止写进程写，在写进程末尾和最后一个读进程末尾V(rw)一下，让别的写的进程能写就好了，如图

![image-20221004100542921](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20221004100542921.png)

但这样写代码是读进程优先，写进程可能饥饿，所以有了下面的写法(reader只锁了前面没锁read()所以reader还是可以并行的)

![image-20221004101943613](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20221004101943613.png)

![image-20221004102000860](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20221004102000860.png)

#### 3.哲学家进餐问题（互斥死锁问题）

- 哲学家拿到两根筷子才能吃饭
- 哲学家拿到筷子后只有在吃完饭才会放下
- 一群哲学家围着吃饭，两个哲学家之间只有一根筷子
- 哲学家只能拿身边的筷子，只能一根一根拿
- 避免饥饿和死锁的情况

这个问题主要是防止死锁和饥饿的情况，假设现在有5个哲学家的情况

我们首先要锁住一根筷子，防止两个哲学家抢一根筷子，死锁的情况先不考虑，于是有下面的算法（都是先拿左边筷子）

![image-20221004103120055](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20221004103120055.png)

那这肯定有死锁的问题

于是可以加一些限制条件，比如

- 至多4个哲学家同时吃饭

或者

- 对每个哲学家编号，奇数号的先拿左边的筷子，偶数号的先拿右边筷子

- 于是有下面算法

  ![image-20221004103709575](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20221004103709575.png)

还有很多别的算法，但实际上没啥好讲的

#### 4.吸烟者问题（轮流生产问题）

- 抽烟要三种材料，烟草，纸，胶水，供应商无限提供这三种材料，但一次只能提供两种材料
- 三个抽烟者a,b,c，三人各有一种材料（无限)
- 三人不停地抽烟，缺材料了会跟供应商要，但供应商只有在上一人抽完了才会提供材料，并且轮流提供
- 这个题就是让三人不停地轮流抽（byd欠抽是吧）

这个问题就是欠抽，本质上讨论如何实现就是一个进程轮流给其他进程提供资源，要加这么多没用的条件，意烟丁真，鉴定为别在这找抽

没啥好说的，供应商进程提供一次锁一次，别的进程抽一次释放一次，这样就行了

![image-20221004110014033](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20221004110014033.png)

![image-20221004110039998](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20221004110039998.png)

![image-20221004110100143](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20221004110100143.png)

## 死锁

之前我们就已经提到死锁了。我们要实现同步，就不可避免地会出现大家竞争同样的资源，互不放手，这样就互相等待了。就像上面说的哲学家问题，一个进程可能会同时占用多个资源，不做完就不会释放，那这样就可能死锁，当然使用信号量不当也会死锁

所以我们来讲一下死锁的必要条件

### 死锁成立的4个必要条件

- 互斥条件：资源必须互斥使用
- 不剥夺条件：资源未使用完不能被其他进程剥夺
- 请求并保持条件：进程占有了资源，但可以请求新的资源
- 循环等待条件：即请求的资源形成了循环等待链

这里只是必要条件，而并非充分必要条件

所以并不是说满足条件就会死锁

就比如说一个资源不止一个，而有进程不在循环等待链里，这样循环等待链就可以被这个进程的资源释放而被打断，如图

![image-20221004141921278](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20221004141921278.png)

### 死锁的处理策略

只要把4个必要条件解决一个，那就能解决死锁了，所以有以下策略

#### 死锁预防

通过限制条件，破环必要条件，从而预防死锁

#### 避免死锁

分配资源的时候，如果分配这个资源可能会死锁，那就不分配，这就可以避免死锁了

避免死锁是在执行时动态地判断，而死锁预防是事先定好规则

#### 死锁的检测及解除

不用任何限制，允许死锁。死锁后及时检测出来，并用某种方式解除死锁（剥夺资源）

当然这样是有损失的

### 死锁预防

#### 破坏互斥条件

让有些资源可以共享使用，但很多资源本身是不可能共享的，就比如打印机，所以这个方法不可行

#### 破坏不剥夺条件

如果请求新资源而得不到满足，那就要放弃自己已经占有的资源，之后再重新申请

当然打印机之类的资源做不到，适用于易于恢复的资源

#### 破坏请求并保持条件

就是运行前一次申请完所需要的所有资源，申请不完就不给资源

当然这样很浪费

#### 破坏循环等待条件

给每个资源上编号，申请资源只能递增地申请，这样就不会循环了

但这种方法一听就很傻逼



### 死锁避免

前面的死锁预防就是操作系统运行前的一些预防措施，但不好用，所以我们在运行时，保证分配的资源不会引起死锁就好了。那怎么保证呢？所以有了下面的银行家算法

### 银行家算法

简单来说就是每次有进程请求资源，就尝试给它分配，如果分配后找不到一个能执行完的安全序列，那么就撤回给它的分配

那怎么找到一个能执行完的安全序列呢？其实如果一个进程在当前能用的资源的情况能执行完，那这个进程所占有的资源都将释放，那么我们只要不断地找能执行完的进程，那么可用资源就会不断上升，那所能执行完的进程就会不断增加，那么找安全序列就是找能执行完的进程，如果找不到了，那说明不是安全序列

### 死锁检测

我们啥都不干涉了，我们就检测是否死锁了，锁住了我们就剥夺资源/撤销进程/回退进程，那怎么检测死锁呢？使用前驱图去找，进程为圆形，资源为方框，里面是资源数，进程的出度为请求，入度为已占有

![image-20221216225800536](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.assets/image-20221216225800536.png)

找能申请到资源并且申请后满足所有请求的进程，去掉和它相连的所有边，重复该过程，直到找不到符合条件进程为止，如果最后没有边了，那么不死锁，否则死锁

# 内存管理

所有的程序需要装到内存变成进程才能执行，那我们应该怎么给程序分配内存呢？

这问题听起来好像没什么要讲的，装就完了呗。但这其实就是大一的数组移动的问题。直接装，很容易留下零零碎碎的碎片，你想用，基本用不了，那内存的利用率就很低了，那你就需要用数组的移动，这玩意又很浪费时间，所以这种方案很他妈傻逼，用着用着就得把内存推一推，清一清内存碎片。所以后面有了分页思想，这个思想其实和局部性原理的思想很像，都是通过足够小的局部的牺牲，来达到整体的高效率，只不过局部性原理靠的是概率上的足够小，而分页则是靠每次分配就分配一个页，而一个进程也最多浪费一个页的足够小

所以我们先讲程序是怎么进入内存的

## 程序的装入和连接

我们写程序的时候总会写include，import等等连接的操作，这其实就是为了方便程序员调用而设计的，但这样一个程序就变成了很多部分了，那么我装进内存的时候就需要把各个部分连接起来，而这又分为

- 静态链接，就是在编译的时候，就把各个模块连接起来编译，这样就得到一个可执行程序，扔进内存就能运行
- 装入时动态链接，很明显，我们大可不必先把各个模块连起来先，装入内存前，你的模块再好也屁用没有，所以你先链接也是没有必要，你在装入的时候链接就好了
- 运行时动态链接，和上面一样啊，你的进程不执行到那个部分，那你那个部分再好也屁用没有，所以我们在执行到需要的部分，我们再把需要的模块弄进来链接，这不就不需要搞一个大大的可执行程序了吗？这样优点是便于修改和更新

那现在程序已经链接了，那我要装入内存了，那内存每个单元有它的物理地址，如果我们的程序的逻辑地址和物理地址一一对应，那我编程的时候，我总不能记着，啊，我的一个程序用了地址a了，那我这个程序就不能用地址a了，那这不是纯傻逼的编程吗？怎么编？而且这样我就能在一个程序改另一个程序的变量，那这不纯纯乱套了吗？根本不能保证安全性。所以我们在程序里写的逻辑地址和真正的内存的物理地址并不是一一对应的，我们要有一个机构去帮我们去映射，这样就不会乱套了。于是我们介绍下面几种装入方式

- 绝对装入，这个实际上是汇编或编译的用到的，可直接填入物理地址

- 可重定位装入，这个就是我们上面说的思想，我们程序里用的时逻辑地址，从0开始计数，而物理地址需要重新映射，但最开始的时候是静态重定位（多道系统），即只是把指令和数据放到一个位置，并且把指令里面的逻辑地址相关的操作改为物理地址的操作，仅此而已，并没有一个机构去帮你映射，如下

  ![image-20221018135614791](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20221018135614791.png)

  没有人帮你记住你开始的地址和终止的地址，程序的执行只是被静态重定位改了指令中的位置而已，所以一旦程序在内存中被移动了，比如从内存中拿出再放回去，那原来的汇编指令就不知道改成啥了，那程序就完全不能执行了。所以静态重定位必须一次分配够程序需要的空间，不够的话就不能装进内存，而且一旦装进就不能部分拿出，而且它不能在运行时申请内存空间（嗯……这里和进程的栈和堆的空间的概念应该不冲突，栈和堆的空间也是申请来的，但我们可能不会一次申请完，但也不可能无限申请，每个进程应该有申请上限卡住）。总之任何跟空间变动的操作，静态重定位都无法做到

- 所以我们有了动态重定位的思想，即每个进程都有一个机构帮你记着你的映射的地址的起始位置在哪，而这个机构就是重定位寄存器，这样我既不用改你的指令和数据，也可以把你搬出内存（因为搬出去了，再搬进来，你指令还是对的，我只要根据当前装入的位置改一下重定位寄存器就好了），如下

  ![image-20221018140917745](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20221018140917745.png)

  上面关于静态重定位的所有问题都能得到解决，还可以实现虚拟内存（好像也可以用到段式管理）

## 内存保护

还是回到原来那个问题，我们上面提到了，你一个程序，故意弄了一个很大的地址，那无论你是绝对还是相对的地址，总会有一个对应的物理地址，那总能访问，修改整个计算机内存里的东西，那这时候就会乱套了，程序之间可以相互干扰了，那就全寄了。所以我们就有了一个很简单的想法，我们进程不会无限大，那么程序的逻辑地址就会有上限，那我们只要有一个寄存器帮我们记着逻辑地址的上限，每次我们一访问/改写一个逻辑地址时，只要看看超没超界地址寄存器，就知道是否越界了

所以一个逻辑地址变成物理地址的过程就是，检查界地址寄存器，没越界就加上重定位寄存器得到物理地址，越界了就报错，如下

![image-20221018143201794](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20221018143201794.png)

## *覆盖与交换（说是不在大纲）

这个就是早期的垃圾电脑的各种解决方案（没有页的概念是这样的）

覆盖就是一个程序分为固定区和覆盖区，这样就可以把进程一部分一部分地放到覆盖区去执行（劣化版的分页）

交换就是第二章的内存调度，把内存的进程挂起放到辅存，从而使得内存能做更多进程

覆盖技术现在已经是一坨屎了，交换技术现在还有一点的生命力

## 连续分配管理方式

终于开始讲具体的分配方式了

下面介绍早期的内存分配方式，即内存的分配是连续分配的（不分页的都是垃圾）

### 单一连续分配

分为系统区和用户区，用户区只有一道程序，所以啥都不用管

### 固定分区分配

把内存分为若干块，每个进程只能占一块（和分页不同的是它这一块很鸡巴大，而且只能占一块）

有均分和不均分两种方案，但都不如人意

![image-20221021155734876](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20221021155734876.png)

### 动态分区分配

就直接往里面装，管它什么分区，一个程序，装就完事了

但很明显这样很容易有内存碎片（没有分页前全是外部碎片，分页后就是内部碎片了）

![image-20221021160338891](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20221021160338891.png)

所以内存做一段时间就得用紧凑技术压一压，很鸡巴傻逼

但我们还是讨论一下我们怎么直接往内存里装吧

- 首次适应算法（first fit）
  - 往下找，找到了就装
  - 虽然简单，但也是最快最好的，但还是有很多小碎片
- 最佳适应算法（best fit）
  - 把剩余空间按递增大小排个序，第一个能装下的空间就装
  - 看起来不错，但查找的开销很大，而且每次都是最佳适应，所以会有很多小空间，根本放不了东西
- 最坏适应（worst fit）
  - 把空间按递减的顺序排，用最大的空间
  - 看起来解决了小碎片的问题，但也导致了大空间没了
- 邻近适应（next fit）
  - 就是改了改首次适应算法，从上次查到的地方开始查。所以也叫循环首次适应算法
  - 但实际上就是导致了内存末尾分裂成小碎片，比首次适应算法还差

## 非连续分配方式

终于讲到页了

页式调入的好处

- 需要时才调入，所以IO更少（不用完全调入，IO时间自然更少）
- 需要的内存更少
- 更快的响应速度（响应速度不是周转速度，每次调入一页，这样每个进程占用的时间都会变少，第一次运行的响应速度自然更快）

### 基本分页存储管理方式

页是进程中的概念，页真正在内存里的物理内存块叫帧/页框/页帧。有了分页的概念不仅有效地节省了内存，还可以把进程部分调入，需要哪一页就从外存调进来，从而我们又提出了外存和内存交换数据的单位，块。

总而言之

- 页——进程
- 帧——内存
- 块——外存

这三个概念是一致的，只有略微差别

当然我们还总是把帧和块这两个概念混着用

然后我们就把逻辑地址的前几位作为页号，然后有个页表，能帮我查我的页号对应内存的帧号是啥（一个进程一个页表）

![image-20221101102214727](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.assets/image-20221101102214727.png)

逻辑地址的后面几位就作为帧内的偏移量就好了

当然我们还是要做内存保护的，不能让你搞个贼鸡巴大的逻辑地址，然后有个贼鸡巴大的页号，那不纯纯的越界吗？

还有注意页表要有当前映射是否有效的标志位，因为映射总有值，你不告诉别人：欸，还没分配页表呢！那别人就拿来映射了

总的页表变换如下图

![image-20221101102924720](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.assets/image-20221101102924720.png)

### 快表

有了页表，那我们就会想用cache的思想，这样就能提高查表速度了。所以我们弄了一个类似寄存器的存储器，叫TLB（相联存储器），也叫快表。要查先查快表（有的处理机快表和慢表（原来的表）同时查，快表查到了就停止慢表的查询），查到了就得到帧号了，查不到就用慢表查，慢表查到了再替换快表里的东西。当然页号是否越界这个是一开始就在做的，和快慢表无关，越界了就中断处理得了。图示如下

![image-20221101104822901](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.assets/image-20221101104822901.png)

### 多级页表

试想逻辑地址的范围为$2^{32}$，如果一页大小为$2^{12}$，即4KB，那么共有$2^{20}$页，如果物理地址范围为$2^{28}$，那么物理页号范围就是$2^{16}$，那页表一项至少要16位，即2B才能记录是哪一块物理页（当然题目也可以跟你说页表项要4B），那么一个进程的页表大小至少$2^{20}\times 2B=2^{21}B=2MB$，那进程一多，内存不直接寄吗？那就算不对所有的逻辑地址进行映射，仅对进程使用的空间进行映射，那么一个40MB的进程，页表项数为$40MB/4KB（页大小）=10K$，那页表项大小为20KB，那这也要10页才能装下了。但更大的问题是这个进程虽然有1万个页，但运行时用到的页数也才几十个，局部性原理非常明显，那我们又想用需要时再调入的想法，我们把完成映射的页表放到硬盘里面，然后再用一个页表去映射完整页表不就好了吗？

一级页表映射二级页表，二级页表映射内存块。查询东西的话在一个页里就不需要再通过页表去映射了，所以我们限制一级页表大小最多为一页。如果一页大小为4KB，页表项大小为4B，那么一级页表最多能记录1024页的二级页表。一级页表根据一级页号一查，缺页，好，去硬盘调页，调回来重新建立映射；不缺页，好，去那个内存页；然后根据二级页号一查，缺页，好，去硬盘调页，调回来重新建立映射；不缺页，好，去对应内存页；然后根据页内偏移量得到对应地址

![image-20221113010030248](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.assets/image-20221113010030248.png)

实际上就是把一页所能记录的页表项数划为一级页号，后页大小的位数划为页内偏移，中间剩下的就作为二级页号

页表就是为了逻辑地址和物理地址的映射，方便编程和保护程序安全，但页表本身还可以利用局部性原理，缺页了再调用，这就带出了虚拟内存的概念，而这个概念本身又可以用于页表本身，这样就可以把页表放到硬盘，仅通过两次查询，就可以换来空间的大大节省，也可以说是时间换空间的

至于多级页表，实际上就是逻辑地址实在是太大了，你就算使用二级页表，二级页表的大小也超过了一页，那你一级页表映射到二级页表一次映射只能映射一页，那你二级页表大于一页的部分怎么办？所以我们有了多级页表的概念。说白了就是假设一页只能装1024个页表项，然后一页4KB，然后逻辑地址共112位，那么我们就需要一级页表10位，二级页表10位，……，十级页表10位，页内偏移12位，共十级页表

### 哈希页表与反置页表

这两种页表我个人感觉就是为了减少页表空间的另一种选择，暂且作为了解吧

哈希页表就是我不用一个数组去记录你每个页的映射了，我直接用哈希表来映射，虽然速度上并不会快，但我只要一个哈希表的大小，而非页号范围大小的数组就能够完成映射的工作了。当然哈希冲突的问题还需要设计良好的哈希函数，不然到后面你的查询速度就慢得一逼了

（哈希页表一般见于逻辑地址较长的系统）

![image-20221113094132360](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.assets/image-20221113094132360.png)

反置页表就是反过来想，页和帧都是一一对应的，那我认为是内存占用一个帧表，映射到进程的每个页，那这样页表大小最大也不过内存空间大小吗？但反置页表的问题在于查表不好查了，如果顺序地查，那这效率太低了。所以我们会利用哈希表，尽量让查询一次命中，虽然这样每个进程又都需要一个哈希表的空间了。

![image-20221113094634940](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.assets/image-20221113094634940.png)

### 分段存储管理方式

这个思想我个人感觉啊，就是连续分配的升级版，连续分配有外部碎片，分页有内部碎片，实际上怎么都有碎片，然后分段式就选择了外部碎片。

分段是有它的好处的，这样你在某一段去查，这一段都是连续的空间（当然段间不连续），这很符合人的思维，查东西在连续的地方查也更舒服，当然连续在很多地方都很舒服。

但我个人还是觉得外部碎片的存在极大的降低了内存的利用率，虽然分段的性能很诱人，但我还是更喜欢分页的思想。当然二者没有什么高低之分，都只是在不同的应用场景的适配罢了，之后我们还会说段页式，这就像是空间和时间的权衡罢了。

还是不说个人感受了，介绍分段怎么个连续分配升级版。

连续分配把程序完全连续分配了，但这其实是没有必要的，就像我们查数据的时候不会去查代码，数据段，代码段，或者分配的其他空间，完全可以分成不同的段去存储，这样就减少了对于过长的连续空间的需求。然后每一段就像是分页映射那样去映射就好了。

但每段的长度都不一样，不像页一样，所以段的逻辑地址，段表和页有比较大的区别。页表的逻辑地址只要固定的分前n位为页号，后m为偏移量就可以了，但在段里面，由于段长不固定，段内偏移量也不固定，所以你不能用固定的偏移量位数去记录。举个例子，分成三段，每段范围如下

- 0段，0~100
- 1段，0~$10^{23}$
- 2段，0~$10^{5}$

所以页的逻辑地址实际上是一维的，也就是说只有一个数值来确定，只是我们能够通过对这个数值的划分来得到页号和偏移量；而段的逻辑地址是二维的，要两个数值才能确定，第一个数值为段号，第二个数值为段内偏移量

![image-20221113133258620](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.assets/image-20221113133258620.png)

当然为了存储的方便我们还是会取最大的段的偏移量作为存储偏移量的空间，但并不代表着这段空间在所有段都是全部可用的，就像上面的例子中的0段只有0~100，那么101~$10^{23}$这部分空间都是非法的（也正是非法的存在，才显得段的逻辑地址空间是二维的）。而非法的判定就由段表去决定

而给出段号和段内偏移量的工作由用户/编译程序去做

说完了段的逻辑地址，我们再来谈谈段表

![image-20221113133915850](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.assets/image-20221113133915850.png)

段表就是一个n行两列的二维数组，一行就是一个段号的段长和其映射到内存的物理地址。段长的目的主要是检查段内偏移是否非法

段式映射过程如下

![image-20221113134310150](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.assets/image-20221113134310150.png)

- 检查段号是否超过段表长度，超过报越界异常
- 查表得到段长和基址，检查偏移量是否超过段长，超过报越界异常
- 基址加上偏移量，得到物理地址

### 段页式管理方式

分页能有效利用内存，分段反映程序逻辑结构并有利于段的共享（好像就是可以针对不同段执行不同的对待方法），那么我们把二者结合起来呢？

每个段都有一张页表，这样段就不必是连续的，而且这样就只有内部碎片而没有外部碎片了

![image-20221113135309438](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.assets/image-20221113135309438.png)

![image-20221113135317646](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.assets/image-20221113135317646.png)

对于段式管理来说，段页式就是对每个段进行了分页，提高了内存利用率，对于页式管理来说，分段就是对程序先分段，再分页，更方便去处理了。这个更方便处理怎么理解呢？就像是你先把人群分为男人女人，然后男人10人一组执行a操作，女人10人一组执行b操作一样，如果你不分组，那你就得10人一组执行操作a，然后看看这一组混入了女的了吗？混入了就得把这几个女的安排到后面，然后开始对女的执行操作b。我个人感觉分段的目的还是方便设计编译程序

然后由于每段的大小也还是不固定的，所以页号的长度还是不能确定，所以段页式的逻辑地址还是个二维地址

映射过程如下

![image-20221113140202849](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.assets/image-20221113140202849.png)

- 检查段号是否超过段表长度
- 根据段号查询，得到页表长度，页表起始地址，检查页号是否超过页表长度
- 根据页号查询，得到帧的物理地址，加上页内偏移得到物理地址

现在的操作系统使用的正是段页式管理

## 虚拟内存

### 需要解决的问题

之前说过，有了页表就可以实现虚拟内存了，但之前的页表的信息量是不足以实现虚拟内存的，而且虚拟内存还需要解决几个问题

- 之前我们的页表虽然说着用时再调入，但那只是我的口嗨，调入一部分在虚拟内存才能实现，因为到了这里我们才开始讨论缺页的情况
- 不完全调入，那我们就不可能避免缺页的情况，但是我们可以减少缺页的发生，从直觉上来说，一个进程在内存占有更多的页数，那么它缺页的概率就会更低。但占有更多页数意味着内存的消耗，内存所能运行的进程数目就更少，那我们该如何把控调整每个进程所占有的页数呢？
- 其次，缺页了的话我们就需要去硬盘调页。但如果内存满了呢？那我们肯定要从内存里把某些页换出，因为一个进程运行过程中真正需要的页数不过十几页，所以大部分页都是无用的。但你怎么知道哪些页该调出呢？说不定这一页现在不用，等下就要用了，或者你刚调出一页，等下又得调回来。
- 还有就是，由于我们都是对内存进行数据修改的，当某一页调出的时候，自然要把数据写回到硬盘，不然你的修改就白修改了。那我们每调出一页就要写回硬盘一次吗？那我们怎么知道这一页对应的物理内存在哪呢？

所以我们先把页表项增加4个字段来解决一部分问题

![image-20221113143713278](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.assets/image-20221113143713278.png)

- 后四个字段就是增加的字段
- 状态位P，记录这个页是否调入了内存。也叫有效位
- 访问字段A，主要用于记录后面的页面替换策略所需要信息，比如访问次数，访问时间等等
- 修改位M，表示当前页是否修改过，如果修改过，那么换出的时候需要写回硬盘
- 外存地址，这玩意我也不知道干啥用的，无视它吧

注意缺页的话我们肯定不会用同步处理，现代操作系统都是基于中断的，所以我们执行程序时，一查页表，欸，无效，不在内存在硬盘，那我就要调入，那就要发出缺页中断，去执行从硬盘调入的动作（如果内存满了，那我们就要执行某些策略，比如替换，比如等待），然后调入后，再把页表对应块弄成有效，再查页表就好了

### 虚拟内存的地址变换过程

![image-20221113144431120](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.assets/image-20221113144431120.png)

### 页面替换算法

我们先解决该替换内存哪些页的问题，所以我们提出了页面替换算法

页面替换算法评价的标准就是

- 引起缺页次数最少的就是最好的





当然每个进程能占有的帧数越多，缺页次数就会更少，但别忘了新的块载入都算缺页，所以你分再多，缺页次数也不会低于这个进程所拥有的页数，所以分配过多的页数是没有意义的



下面我们开始讲各种换页算法

#### 先进先出页面置换算法(FIFO)

这个算法看起来没啥问题，但唯独它可能会出现分配的帧越多，缺页次数反而越多，这称为belady异常

这主要是因为先进先出和顺序相关，而引用串也可能正好和它的顺序差一点，导致大部分帧可能刚被换出就被换入，从而导致belady异常

#### 最优替换（optimal，OPT）

未来最远才被调用的帧被替换。所以这个算法是上帝视角，我们并不知道未来会调哪个帧。只有理论意义，或者说给出了置换算法的上限在哪，从而看出一个算法的效率如何

其实我们不同算法都是基于不同的假设去做的，比如有的就假设以前的调用的概率高，有的就假设新的调用概率高，其实就是对应不同的应用场景

#### 最近最久未使用（LRU，least recently used）

不能看未来，那我们就看过去。最近最久未使用的帧被替换。这个其实就是基于最近最久未使用未来用到的概率更低的假设。主要是对应我们现实中的很多情况。

一个简单的想法是给每个页被访问时打上一个时间戳，这样遍历一遍就可以得到要删哪个了。但时间戳要调用时间中断，这样很慢，而且页之间的时间差可能很小，那这样你的时间戳的单位就会很小，数值就会很大，光是存储这个时间戳就要花费大量空间

一个改进的方法是页面的先后用堆栈存起来，如果查某一个页面，在堆栈里的话就把它拉到栈顶，不在的话就踢掉栈底的页面，然后把查的页面压到栈顶

#### 二次机会法（时钟(CLOCK)置换算法）

这个算法并不打算踢出最久未使用的页面，所有页面组成一个循环数组，如果查表没找到，就从循环起始位循环所有页面，如果页面被调用过，那么把标志位改为未调用，然后下一个，直到找到一个未调用的页面，把它踢出换入要调入的页面，然后循环起始位变成当前位的下一位；如果查表找到了，就把表的标志位改为已调用

![image-20221113165152551](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.assets/image-20221113165152551.png)

实际上就是如果你被调用过，那么你还有第二次机会不被踢出去，从而减少常调用过的页面被踢出去的概率，所以二次机会法就是LRU的简化版，效率也低于LRU，但实现和消耗都好于LRU

#### 计数算法

我懒得管最近不最近了，我就默认开机到现在，这个页面到底被调用了几次，然后根据计数的多少分为

- LFU，least frequently used，选择计数最少的替换，这个算法默认最少使用的页，未来使用的概率最小
- MFU，most frequenly used，选择计数最多的页进行替换，这个算法默认最多使用的页，未来使用的概率最小

### 页面分配策略

每个进程在内存到底该占有多少页呢？是全满足吗？是按比例分配吗？还是平均分？这些想法似乎都不是很好。我们总想让内存并行更多的进程，却又不想提高进程的缺页率，这是很矛盾的，但我们还是想想办法吧

先来讲讲局部替换和全局替换的概念吧

换帧两种分法

- 本地替换，换的帧是自己进程占有的帧（这样一个进程占的帧数不变）
- 全局替换，换的帧是从全部的帧中挑（这样占有的帧数会变，可能会有进程很多帧，有的进程就快没有了）

然后现代的操作系统通常采用以下三种策略

#### 固定分配局部置换

固定就是不变的意思，每个进程整个运行期间所占有的页数不变，缺页了就用之前的页面替换算法，局部置换。这样最大的问题是我们并不能很好地给每个进程分配合适的页数，要么过多浪费内存，要么过少缺页率过高

#### 可变分配全局置换

对全部的页使用页面替换算法，全局替换。当然也会维护一个空闲页队列，有空闲就不用替换了。这样最大的问题是很容易一个进程占有的页数越来越多，另一个进程占有的页数越来越少的情况（毕竟页面替换算法可没有考虑页数问题）

#### 可变分配局部置换

让我们再回到问题本身吧。分配多了缺页率低内存浪费，分配少了缺页率高内存节省，那我们实际上可以用缺页率作为评价标准，只要控制缺页率在合理范围，那么分配就是刚好合适的

所以分配方法就是，每个进程一开始都有一定数量的页，如果缺页率过高，就再分配一些空闲页，如果缺页率过低，那么就使用替换算法释放一些页。



这里再多嘴几句总结一下目前常常用到的思想

- 可变与固定，动态和静态。动态调控一般来说都好于静态，但动态最大的问题是需要不断计算，计算本身也是一种开销，权衡调控节省和计算开销是我们一直在做的事情。动态就是用来解决我们总觉得固定去做不能兼顾的问题的
- 时间和空间，这个就不用多说了
- 局部性原理，实际上就是权衡后的结果
- 公平和高效，还有牺牲。任何行为都是有代价的，顾此失彼是常态。局部性原理好就好在它可以牺牲一点而获得很多，而在局部性原理无法使用的时候，我们就得考虑要牺牲哪一部分了。如果我们想要二者兼顾，那么牺牲的代价就得均摊到每个人头上。总想着逃避牺牲反而会想不出解决方案

### 抖动

抖动的本质就在于你分配给进程的页数少于局部性所需要的页数

# 文件管理

windows默认扇区大小为512字节，但NTFS文件系统以扇簇为单位进行管理（这里为8扇区4KB）。由于上述文件太小，若直接占用磁盘空间将造成极大浪费，所以上述文本文件存放在$MFT元文件的属性中。简单来说如果一开始的文件大小（大概在600B左右）太小，那么就不会申请磁盘空间，即在“属性”那里就会显示“占用空间”为0，大小为字符对应大小。而大小到达存入磁盘的标准时，就会申请磁盘空间，而且是最少申请8个扇区，即4KB，而申请后，如果文件大小比占用空间少比较多（.txt测试时少4KB）时，就会释放一定的空间

![image-20221111142917186](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.assets/image-20221111142917186.png)

![image-20221111143032264](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.assets/image-20221111143032264.png)

![image-20221111143101062](%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.assets/image-20221111143101062.png)

## 文件硬盘空间分配

### 连续分配

空间连续，空间存储效率高（主要是连着放就好了，没什么计算成本），访问方便

但外部碎片，文件不能变长或变长的范围受限

### 链接分配

每个块存了一个指针，指向下一个块，然后文件的目录记录了起始块的地址，然后访问块就从起始块开始读

其实就像链表一样，这样虽然没有外部碎片了，但也不能像以前一样随机存取，每读一个块都要从头开始一个个读

### 索引分配

不得不说操作系统和数据库的作者是确实同一个，说来说去又说回来了

就是用一个索引表，索引所有的块，但和页表，和数据库的索引有一样的问题，一个表大小就一个块的大小，那么表所能记录的块数是固定的，你每个记录的范围增大，每个块所能记录的记录数反而会更小，所以和页表和数据库一样，它也可以弄多级索引，但这样的速度也就慢下来了，当然还是比连接分配的速度快。

当然表还有问题就是占用空间

所有算法在没法优化的情况下，都是时间和空间的互换

然后unix每个文件一级，二级，三级索引都有，文件很小，那么一级索引就够用了，大了就启用二级索引，再大就用三级索引

## 空闲空间管理



## 硬盘交替编号，错位命名

> 减少延迟时间的方法（原理：读完一个扇区后需要一段时间处理才可以继续读入下一个扇区)

**交替编号**：物理上相邻的两个扇区无法做到连续访问，因为访问完上一个扇区后，需要一段时间处理，而这个时候磁盘的旋转并没有停止，等到可以访问的时候，可能已经过了。故可以使两个逻辑相邻的两个扇区的物理编号有一定的间隔（一个磁道被分为6个扇区依次编号为1 4 2 5 3 6转两圈访问完所有的扇区）

**错位命名**：（假设有八个柱面 4个盘面 8个扇区 二进制表示为000 00 000 ）

0号盘面的0号扇区对应的1号盘面的0号扇区是错开的，原因同上（一次只能读一面？）。

当访问物理地址为000 00 000~000 01 111的扇区时

访问物理地址为000 00 000~000 00 111的扇区时，0号磁盘上的磁头激活，磁盘转动两圈

访问物理地址为000 01 000~000 01 111的扇区时，1号磁盘上的磁头激活，此时需要一段时间处理信息，所以应该将000 01 000与000 00 000错开。这样等可以访问时，第一次划过物理地址为000 01 000的扇区就可以进行读取了，缩短延迟时间

> 磁盘地址结构设计

为什么设计成 柱面号 +盘面号+扇区号的结构而不是 盘面号+柱面号+扇区号

因为前者访问00000111~00001111 不用移动磁头 只要激活1号磁盘上的磁头

后者需要移动磁头壁切换磁道，物理的移动时间比较长（只有柱面号需要切换磁道，所以我们希望柱面号在高位，这样地址增加很难改变柱面号，而盘面号也需要切换磁头，所以我们把它放到次高位，扇区的切换是很轻松的，所以我们放到最快变化的最低位）

# I/O

磁盘高速缓存

- 首先注意，这玩意不是之前说的cache，原理和cache一样，只是用的不是SRAM，而是内存，用内存作为内存和硬盘间的cache

缓冲区设置的目的，SPOOLing技术的原理

- 有个人a干活很快，一次能干10件事，某人b干活很慢，一次只能干1件事，现在a要给b发任务，a要b干13件事，但b脑袋不行，一次只能记住一件事，好家伙，那a就得告诉b一件事，等b干完了，再告诉他下一件事，a站在那半天，感觉啥事也没干，人麻了
- 然后a就想到了一个法子，a把要干的事情全写在本子上，b要干活，看本子就行，a可以逍遥快活去了
- 本质上就是以空间换时间，缓冲区是用内存的空间，SPOOLing技术则是用硬盘的空间