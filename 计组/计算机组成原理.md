# 计算机组成原理

## 小小地概括一下

什么是计组？就是计算机组成原理嘛。那计算机由什么组成，又为什么要由这些部分组成呢？那我下面细说这些问题

计算机由什么组成？至少得有CPU，内存，外存，输入输出设备，总线。CPU负责计算，控制，执行指令，而程序运行时给出的指令，就存于内存之中，CPU就从内存里读出执行这些指令，写回数据到内存里。这样看起来，好像已经完成了计算机的功能了，但还不够，内存还不能在断电的情况下保存数据，这也意味着如果我们重启电脑，我们就得手动再把程序一个一个输入进去，太傻逼了，这也是冯诺依曼体系的特点，程序存于外存中，执行程序时，便在内存里开辟一个空间，把程序放到里面，申请的变量也在里面申请，这就有了进程的概念了。但这还不够，因为没有输入输出设备，这台电脑根本毫无意义。这么多设备，每个设备之间都用线连起来吗？不，太浪费且设计太复杂了，所以我们又引入了总线，所有数据都通过总线来传输。这样，一台计算机就成型了

于是我们便要对每个模块深入地剖析，这就是每个章节的内容

我们先对存储系统进行讲解。我们先讲了芯片的能力，知道了ROM一般用于不修改的程序的保存（比如操作系统的一些东西？），SRAM用于cache，DRAM用于内存。然后继续宏扬时间空间局部性的思想，利用存储分层的思想，在CPU和内存中间加入cache提高读写速率，把外存看作内存的一部分，把内存看作外存的cache，从而扩大了内存的容量，实现了虚拟内存。而cache本身只能存下内存的一小部分的数据，所以我们又提出了三种数据块的映射方案。在实现虚拟内存的时候，我们同样用映射的思想去实现，并且提出了操作系统才学到的页和段的内存分配的概念（所以才会学不懂）

后面的不想写了，爱咋咋看吧

# 第三章——存储系统

## 一些概念解释

### 容量的各种表示

字：若干比特组成的ALU操作最小单位，一般可以认为指机器字长

字长：一个字有多少比特，这就是字长

字数：有多少个字，这就是字数

机器字长：计算机进行一次整数运算所能处理的二进制数据的位数（整数运算即定点整数运算），简单来说就是ALU处理的数的位数，而ALU处理的数是由CPU的内部数据通道传过来的，所以机器字长也是CPU的内部数据通道的宽度

存储单元：可以看到存储器是一行一行的，这一行就是一个存储单元，地址线所能选出的就是一个存储单元，存储的最小单位，长度一般为字节的整数倍，所以如果存储字长大于字节，就算我们只对一个字节操作，计算机也要对一整个字进行操作

存储字长：就是一个存储单元的位数

例如存储器容量 $$64k\times 8$$ ，表示有64K个存储单元，存储字长为8，也可以理解为有64K行，8列

按字编址和按字节编址：这两个概念我觉得挺扯的，存储器本身只能按字编址，寻址的最小单位就是字，而我们日常编程就是按照字节编址，会把存储器读出来的字继续处理得到对应字节，所以提这两个概念干嘛呢？我感觉就是为了纯粹出题，问你按字编址寻址范围，按字节编址寻址范围等等

大端，小端：老生常谈了，但我想用一种更好理解的方式去表示，如下

> 存的东西：0x12345678
>
> 地址			大端内容		小端内容
>
> 0x4				78					12
>
> 0x3				56					34
>
> 0x2				34					56
>
> 0x1				12					78

这样就比把数据左右排更能理解大端小端，即我们读东西都是从低地址往高地址读，即低地址是前面，所以把数据大的位放在前面的放法是大端，把数据小的位放在前面的放法是小端



### 同义词解释

内存——主存

硬盘——磁盘，辅存

虚拟内存——即进程（具体概念请到操作系统笔记的一些碎碎念了解）里显示的地址是一个相对地址（即地址都是从零开始计数，但我们内存不可能只给一个进程使用，所以地址都是要经过文件管理系统去翻译跳转的，这部分请到操作系统笔记了解），所以每个进程看起来都是独自占据了内存，但我们没必要把占据的东西局限于内存，只要是能存东西，进行读写，我们再配套上对应的相对地址翻译功能，那我们的进程看起来就占据了一个空间自由使用，那这就是虚拟的概念，这就叫虚拟内存。所以虚拟内存的实现就是把硬盘也看作内存，并且使用时间局部性和空间局部性来使读写速度逼近内存速度，从而大大扩大了存储容量

## 半导体随机存储器和只读存储器

RAM可读可写，ROM只能读不能写，在出厂或烧了之后就不能改写了，主存主要分为RAM和ROM两大部分

## 几种RAM存储单元及其特点

S的意思是static，即静态的意思，D的意思是dynamic，动态的意思

### 6管SRAM记忆单元

用双稳态来存储信息，只要供电就信息就不会丢失，断电就会丢失，这就是半导体存储器的易失性

存取速度快，但集成度低，功耗较大，所以一般用来组成高速缓冲存储器和小容量主存系统

### 4管DRAM记忆单元

用电容来存储信息，电荷会泄露，所以每过几毫秒就要刷新一遍，读出信息时就会向电容中补充电荷，所以刷新过程就是读出过程，刷新就是假读（这也意味着断电就会丢失信息）

集成度高，功耗小，但存取速度慢，一般组成大容量主存系统

### 单管DAM记忆单元

读出是破坏性读出，所以读出要重写，即信息再生，这就很耗时间（重写和刷新不同，刷新是定期补充电荷，重写是读出后恢复信息）

比4管DAM功耗更小，集成度更高

### DRAM的刷新

之前说过了，DRAM每隔一段时间要刷新，这个刷新周期我们取最大能维持的时间，即在这个时间内，所有存储体应该都刷新一遍

#### 刷新方式

刷新间隔：全部刷新的时间间隔

刷新周期：刷新一行要的时间

刷新时间：刷新完所有单元花费的时间

刷新时不能进行读写操作

![image-20220429184631970](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220429184631970.png)

由于DRAM刷新就是假读，所以刷新周期就是存取周期（存取都是以一行为单位的，比如字节）

那就有刷新时间怎么安排的问题了

存取和刷新都只能在对应时间槽的开头发起

于是有以下几种方式安排

#### 集中式

![image-20220429185041543](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220429185041543.png)

刷新周期全放到最后

好处就是存取不会受刷新影响，存取速度较快

缺点就是刷新周期都放到最后，这段时间都不能操作，称为死区，一等就要等很久

#### 分散式

一个存取一个刷新

![image-20220429185316884](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220429185316884.png)

好处就是没有死区

缺点就是存取周期变成原来的两倍，存取速度明显下降，其次刷新过于频繁，上面2ms只要刷新32次，这里32us就要刷新32次，浪费了最大刷新间隔

#### 异步刷新方式

就把集中式的每个周期均分到读写中罢了

![image-20220429185627730](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220429185627730.png)

这样虽然也有死区，但死区只有0.5us，避免等待过长时间，又充分理由了最大刷新间隔

#### 不定期刷新

都说刷新是假读，那么读的时候就不用刷新，不读的时候刷新就好了，这样就能消除死区了，又不会降低存取速度，但控制比较复杂，实现较为困难

#### 刷新控制

当刷新和读取冲突时，优先刷新。有些DRAM自带刷新功能

注意：存储器是多个芯片组成的，每个芯片可以看作二维排布的存储单元的集合，而刷新操作是所有芯片同时操作的，所以刷新时是所有芯片的某一行都被刷新，所以刷新时间看的是单个芯片存储容量（芯片有多少行），而不是整个存储器的容量

### RAM芯片分析

下面说的还只是一个芯片的事，没到一堆芯片的问题

RAM芯片有地址线，数据线，控制线，外部和芯片联系就靠这三种线。控制线又有读写控制线（有些SRAM有两条，有些一条）和片选线，片选线用来表示该芯片是否被选中某个芯片，地址线（只读）用来读一个芯片的某行，数据线（可读可写）读或写数据

![image-20220429210718191](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220429210718191.png)

举个例子，一个芯片容量为$$1024\times 4$$，即1024行，4列，或者说数据位数为4，那么地址线就要10条（$$1024=2^{10}$$，所以10条），数据线要4条

由于DRAM集成度高，容量大，地址线可能会很多，那我们把地址线分成两部分传进入就好了，前一次输入的称为行地址，后一次称为列地址，都从同一组地址线传进入（这样增加一条地址线就相当于增加两条），用额外的信号去控制就行（行地址选通信号，列地址选通信号），这样我们就不用设片选线了，用行选通和列选通兼做片选信号

#### 地址译码方式

说白了就是我们怎么找到某一行的

或者说芯片本身怎么组织行，芯片自带的地址译码器怎么转换到具体的某一行中

先摆脱一行就是长长一条的印象，要找到某一行就要找到某一行的数字，即地址，那这个地址，可以一维地存，也可以二维地存，甚至多维地存，对吧（想想多维数组的实现）。一维地存，那么数组的序号就和地址数量一样多，对吧。那如果二维地存，数组行和列的序号就可以是地址数量开根后的结果了，这很爽吧

所以有以下两种组织行的方式

##### 单译码方式

即行的排列是一维的

![image-20220429212858607](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220429212858607.png)

这样地址译码器要引出去的线就贼鸡巴多

这种结构的优点是结构简单，缺点是外围电路多，成本昂贵，而且随着行数增加，会形成一个方向巨鸡巴长的不合理的情况

读写时都是一行一行地读的，即一读一字（这里的字不是指之前两个字节那么长的字，而是指一行有若n位，n位即为一字）

##### 双译码方式

行的排列是二维的

下面这个图是双译码芯片的某一层的结构

![image-20220429214613973](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220429214613973.png)

这个图里的矩阵的元素不是上一个图里的真正存储的元素的意思，而是某一行的意思，靠两个译码器选行选列选到某行某列的那一行。而要实现这一行有n位长，那就要在z方向上叠加n层，这样我们就能取出一行了

当然上面这种组织方式叫位结构，还有一种叫字段结构，就是不用叠层的方式访问一行了，在行列选择的时候，行选择和原来一样，列选择的话一选同时选b列，这样就能不用叠层就能选出一行了

可以看看两种方法的线的差别

![image-20220429233952424](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220429233952424.png)

#### RAM的读写时序

##### SRAM读写时序

![image-20220429234316860](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220429234316860.png)

可以看出片选信号cs是在地址线确定之后才有效的，写允许信号在读周期保持高电平，写周期低电平

##### DRAM读写时序

![image-20220429234609219](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220429234609219.png)

可以看出行地址要在RAS行允许信号有效前有效，列地址也要在CAS列允许信号有效前有效

读周期时写允许信号要无效，写周期时数据输入和写信号必须保持到CAS变为低电平之后

## ROM的介绍

### ROM的类型

ROM要编程完成第一次写入，根据编程方法的不同，可以分为以下几类

#### 掩模式ROM（MROM）

由生产商根据用户需求写入，一次成型，不能再改

优点是可靠性高，集成度高，批量生产价格便宜

缺点是对制造厂过于依赖，灵活性差

#### 一次可编程ROM（PROM）

用户可以用专门的写入设备写入，写入后不能再改

写入的原理是出厂时将记忆单元全记为0或全记为1，通过将记忆单元熔丝烧断或PN结击穿，以此让记忆单元表示0或1，所以不可逆

#### 可擦除可编程ROM（EPROM）

可以看作上面的升级版，可以多次改写

出厂时存储单元全为1，用户可改写为0，之后要更新的话，又可以把0擦除，即恢复全1

擦除方法有紫外线擦除和电擦除

- 紫外线擦除（UVERROM）

  擦除的仪器就是个紫外线灯，一照，0单元就全变成1了（所以不能针对地擦），而且为了防止日光紫外线的影响，必须用不透明的黑纸将芯片的透明窗口封住

- 电擦除（EEPROM）

  用电气方法擦除，可以擦选中的存储单元，可以擦某个块里的单元



那又能写又能读，还是持久化的，为什么不能取代RAM呢？

- 写的次数有限
- 写花费的时间过长，是SRAM或DRAM的100~1000倍

#### 闪速存储器（flash memory）

简称闪存，可以看作快速版的EPROM，既可以不加电长期保存信息，又能快速擦除和重写

闪存又分为NOR型和NAND型

- NOR型

  擦写时间很长，但可以随机存取存储器上的任意区域

  和RAM的读取方式很像，这让它非常适合替代老式ROM

- NAND型

  擦写时间较短，但读取必须以区块为单位

所以在微型计算机的主板上用闪存来存BIOS程序（很重要，不允许修改）,用闪存的好处就是，在想升级BIOS的时候不用换整个芯片，而且闪存是低电压改写，这样微型计算机不用担心电压问题

### ROM芯片介绍

主要用的ROM还是EPROM，所以下面介绍的是EPROM的引脚

![image-20220430084012417](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220430084012417.png)

和RAM差不多，就读写和变成的差别

## 半导体存储器的封装

上面的标题什么意思？说白了就是我们上面介绍了那么多芯片啊，原理啊，最后到了市场都是一种产品，那有那几种产品，产品本身又有哪些特点呢？

### DIP存储芯片

双列直插封装（dual in-line package，DIP），特点就是要焊在主板上才能使用，所以更换很麻烦

容量不是很大，如 $$256K\times 1$$，不是之前芯片的意思，这个意思是有256K个存储单元（并不想表示行列），所以256KB的信息要8个这样的芯片，若还要奇偶校验，1B有8b，最后还得加一位奇偶校验，那就得9个这样的芯片

### 内存条

单列直插存储模块（single in-line memory module，SIMM），双列直插存储模块（dual in-line memory module，DIMM），Rambus直插存储模块（Rambus in-line memory module，RIMM）

上面说的这些都是内存条

内存条实际上就是多个存储芯片焊接在一起的电路板，外面引出多个接口，插在对应的插槽上就相当于接上了，所以可以随意拆卸

![image-20220430090702609](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220430090702609.png)

SIMM有30线和72线两种（线不全指数据线，还有很多用于其他功能的线），30线的版本只有8位数据线（部分会9位，一位奇偶校验），所以想组成32位的存储系统要有4片SIMM一起构成，72线的版本有32位数据线（无奇偶校验的数据线）或36位数据线（有奇偶校验的数据线）

DIMM有多种。标准的DIMM为一面84线，由于有双面，所以共有168线

## 主存容量的扩展

芯片容量总会不够的，所以要把芯片连起来

可以计算需要的芯片数

![image-20220430092357111](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220430092357111.png)

有几种扩展方法

### 位扩展

即加大字长，这就意味着芯片的字数要和要实现的存储器的字数一致

如 $$64K\times 1$$ 芯片要扩展到 $$64K\times 8$$ ，那选地址的时候，所有芯片都共用一个地址线，读写信号，片选信号，然后I/O输出再并联起来就好了嘛

![image-20220430102424045](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220430102424045.png)

### 字扩展

即加大字数，所以芯片的字长要和要实现的存储器相同

我们选了n个芯片，那我们增加$$log_2n$$个地址就好了，增加的地址通过译码器去选中某片芯片，原来的地址输入选出某行，然后输出就好（其实其他原来的信号都是共用的，就用片选信号来控制是否接收这些信号就好了）

![image-20220430103013623](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220430103013623.png)

### 字和位同时扩展

![image-20220430103349772](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220430103349772.png)

## 提高存储系统访问速度

### 双端口存储器DPRAM

现在计算机都是多核的，CPU有多个，我们虽然不能提高内存存取速度，但如果我们能让两个CPU同时读写这个内存条，那就变相地提高了速度

下面介绍几种情况

- 同时读同一个字——允许（所有操作都是在时间槽的开头开始的，两边一起读，读出的结果分到两边就行了，不是读出后又能瞬间读出的意思）
- 同时读不同的字——允许
- 同时写不同的字——允许
- 同时写同一个字——禁止
- 一端读，一端写同一个字——禁止

那禁止的情况怎么解决呢？

我们加一个标志，告诉别人一端现在是不是在写就好了

所以设置了BUSY标志线，一端一个，有效的话这一端就要延迟执行读写操作，而是否有效由逻辑部件去判断

逻辑部件的判断我还没弄明白

### 单体多字存储器

之前我们的芯片也好，存储器也好，一次都只能读出一个字，实际上读出这个字后存储器本身就会僵直一段时间，用来恢复数据之类的，这就拖累了我们存取的速度

那我们换一种思路，我们还是一次读出一个字，但字长是原来的n倍，把这个长长的字存到寄存器中（这样就是并行了），让CPU一个一个取，等CPU用完了，我们的僵直也完事了，又可以放长长的字进去，这不就能提高存取速度了嘛

这就是单体多字存储器，存储器还是只有一个，只是一次读出多个字提高速率罢了

但这样还是有问题，如果我刚读了一个长长的字，结果僵直还没缓过来，就收到跳转的指令，要访问另一长长的字，或者我要的数据不在同一个长长的字中，那就会访问主存冲突了

很明显，这样访问主存冲突大，提高速率不明显

结构如下图

![image-20220430153703717](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220430153703717.png)

> MDR： memory  date  register，主存数据寄存器
>
> MAR： memory  address  register，主存地址寄存器
>
> $$M_i$$： 在这里表示一个长长的字里的一个字

### 多体单字存储器

那一个存储器会僵直，那我们用多个存储器缓解僵直不就好了吗？

这又引申出两种编址方式

#### 顺序编址

一个存储器里的地址是顺序的，即一列一列地往下数

![image-20220430155137458](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220430155137458.png)

这时候我们访问某个地址时，地址的高位是选择模块，低位是选择该模块的地址的字

但很明显啊，这并没有缓解僵直啊，你顺序访问（其实就是串行），在一个存储器里面该僵直的还是僵直啊，还没访问单体多字快

取一个字就等一个周期，那取m个字，就得等m*T这么久

或者从另一个方面说，这只是之前字扩展的技术罢了，只是扩容

不过这样一个模块坏了，访问其他模块还是没问题的

#### 交叉方式——多体交叉访问存储器

那我们想要提高速度，那肯定要并行啊，你串行肯定寄

那我们沿用单体多字的思路，一次访问多个字，但之前不是说不行了吗？别急，之前单体多字一次访问了多个字，不也要存在寄存器里等CPU来一个一个取吗？那我们一个接一个地从不同存储器取出顺序的字，让存储器轮流工作，不就能解决问题了吗？（有点像双通道，不清楚）

编址如下图

![image-20220430160254677](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220430160254677.png)

一行一行地数

地址高位选择模块的某个字，低位选择模块

但这很明显的啊，有一个模块坏了，整个多体存储器都受影响

结构如下

![image-20220430160606002](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220430160606002.png)

那速率怎样呢？如下图

![image-20220430160657575](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220430160657575.png)

$$\tau$$是总线上传送所要花费的时间（从存储器中取出数据的时间可忽略不计？这样的话那僵直是真的久啊）

上图的矩形是一个模块的存取周期T，可以看出一个模块僵直了，其他模块就顶上，这样当所有模块都读过后，第一个模块的僵直也结束了，就可以完成无缝连接，看似没有僵直了

也可以从图中看出，取了m个字，花费的时长就是（T+（m-1）*$$\tau$$）

记$$T/\tau$$为交叉存取度

### 高速缓冲存储器

就像我们认为的那样，如果要在某方面登峰造极，那就得牺牲一部分东西。而我们的存储系统想要做到的就是又快又大，这就很矛盾，几乎不能实现

那怎么解决呢？矛负责锋利，盾负责坚固，二者不用同时兼备他人的优点，用矛和盾的人能兼具这二者的优点就行了，需要用矛的时候用矛，需要用盾的时候用盾，这不就好了嘛

再回到高速缓存，我们有快的有慢的，最快的高速缓存SRAM可以接近CPU的速度，那我们一级一级地向外扩展，每一级都比上一级慢，但容量又大很多，这样在一级找不到的时候，再往外一级找，如此以往

那你又会问了，那这样一直找，不就更慢了吗？别急，我们程序没有这么随机，有时间局部性和空间局部性

时间局部性指一个单元被访问了，那么之后很可能也会被访问，因为有循环存在

空间局部性指一个单元被访问了，那么之后临近的单元也可能会被访问，因为程序的大部分指令都是顺序存储，顺序执行的，数据一般也是数组，树等簇聚在在一起的

那我们放在高速缓存的数据大概率会被访问到，越到外面的数据概率就越小，这样就像我们大概率用矛，就保持攻击模式一样，出错了的话，从期望来说也不会低

#### Cache的基本结构

我们把高速缓存记为Cache，Cache的基本结构如下（别急，看不懂正常）

![image-20220501082233200](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220501082233200.png)

#### Cache的读写操作

注意，我们CPU读写的最小单元是字，但我们在cache和主存之间数据交换是以块（一个块多个字，也称作行）的形式去读写的

计算机的存储分很多层，从内到外为cache，内存，硬盘，不同层去交换信息都是以某个数量的比特去交换，而不会是一个一个比特去交换，这部分想了解更多去操作系统笔记的一些碎碎念看

![image-20220501105042981](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220501105042981.png)

这样高（m或c）位就是块号，低b位就是块内地址，整个地址就是真实地址

命中：即访问的东西能在Cache里找到

缺失：就是没命中

cache命中率：cpu访问cache没找到自然回到主存里面找，所以cache命中的次数C在cache命中C和主存访问次数M的和的占比就是cache命中率H，用公式表达为

- H=C/(C+M)

cache-主存系统平均访问时间：这就很容易理解了，拿cache命中的占比，主存访问的占比乘上对应的访问时间再加起来就好了

读写操作

- 读操作

  Cache命中，就从Cache里读，没命中，就到外层，主存里找，并把找到的信息调入到Cache里，如果Cache满了，那就要替换掉一些存储单元里的信息，这就涉及到替换算法（后面讲）

- 写操作

  那我们如果要写数据又要快的话，那就要写在Cache里

  那如果命中了的话，写了Cache之后，我们什么时候把修改的数据写到主存里呢？

  这又有两种方法：**写直达法**和**写回法**（后面讲）

  那如果没命中的话，即写缺失，就直接写入主存，这又有两种方法

  **不按写分配法**：只写入主存

  **按写分配法**：写入主存后，还要从主存把这个块读入Cache，缺点是每次不命中就要传送一个块

#### 地址映像

简单来说就是主存的块放到到Cache放到哪个块的问题

这是问题吗？这问题挺大的

如果你找空的块放，那你怎么知道Cache哪个块空了？找到要不要代价？电路复不复杂？成本高不高？

如果主存的块就指定到Cache的某个块，主存容量远大于Cache，那肯定会出现大量主存块竞争一个Cache块的问题，即便Cache的其他块是空的。那这个Cache块就得频繁去主存找，这样速度就大大下降了

那我们就这两个思路顺下去

##### 全相连映像

就是第一个思路，主存的块可以放到Cache任意块中

![image-20220501090755693](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220501090755693.png)

这样优点是冲突概率最低，空间利用率最高

缺点是这样要找到对应地址就要地址变换（记住是块号变换），由于可选范围太大，地址变换速度慢，也要替换算法，成本高，实现困难

那具体是怎么实现的呢？

我们的CPU都是直接找地址的，我们再弄个查找映射，把主存地址映射到Cache地址，这太他妈麻烦，更他妈慢，这不行

那我们不想对传过来的地址处理，直接对这个地址进行不同的解读就好了

那我们现在有很多问题了。我们怎么在一堆的从主存复制过来的，存于Cache中的块中找到我们想要的块，怎么知道Cache有没有我们想要的块？我们怎么去解读这个地址呢？下面我们一起来讲

很遗憾，由于Cache为了空间利用率，也因为容量，我们并不能将来自主存的块按顺序排列，也就不能直接靠地址访问到，也无法靠算法去解决，只能全遍历一遍，才能知道是否有这个块。而辨别不同块的标志其实很简单，我们让地址高位作为块号，低位作为内的偏移量就好了。所以块从主存复制到Cache，也会附带主存的地址的高位

如地址 0xFF0144，一个块有32个字节，则地址全映射的划分为

![image-20220501160114639](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220501160114639.png)

低5位作为偏移量，剩余的高位（这里没有写错，由于低位是5位，导致高位左侧加了一个0，右侧少一位数，所以成这样，具体高位有几位，这要看主存的地址有几位，主存地址位数 - 块的大小的位数 = 高位位数）作为块的标签（tag），让遍历过程去比较

而实现这个遍历过程的机器就是内容可寻址储存器CAM

CAM读入一段数据，和CAM里面存的数据进行对比，注意，是同时对所有数据进行比对，相同就输出这个数据的地址，如下图

![image-20220501161040345](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220501161040345.png)

而我们的Cache存储的结构是这样的

![image-20220501161141951](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220501161141951.png)

Cache前面是所有块的标签，称为Cache目录，实际上并不是堆在前面的，而是长这样的，如下图

![image-20220501171947054](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220501171947054.png)

第一位是这个块是否被占用的有效位，绿色那段是标签，后面的就是块里真正存的东西，而一个块就是一行

那CAM是如何做到同时读入所有标签的呢，举个例子

![image-20220501172258666](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220501172258666.png)

可以看到CAM和Cache并没有分得很清楚，CAM实际上就是读出所有标签，每个标签都同时比较而已（就是图中的“=”），可以看出这样比较的东西一多，电路就会急剧复杂

从全相联Cache读出的过程：Cache收到CPU的地址，然后把地址分为标签和偏移量，CAM读入标签，给出这个块在Cache存的地址（是把这个块的数据读出后再偏移还是偏移后再输出，我倾向于前者，从上面的实例可以看出是读出了整个块的数据，然后4选1输出，所以后面的说法不一定对），或缺失然后告知，找到块的地址了，再在这个地址的基础上偏移“偏移量”这么多位，得到要访问的内容在Cache中的地址，这样就能读出我们想要访问的东西了

##### 直接映像

就是第二个思路

![image-20220501091208059](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220501091208059.png)

简单来说映像规则就是：映射到的Cache块号=主存块号  mod  Cache块数

这样冲突概率最高，空间利用率最低

但设计简单，成本低，易实现，地址变换速度快，不涉及替换算法

具体实现怎么实现的呢？

我们当然想沿用之前全相联的思路和模板，这样也能兼容，更好

我们还是把传来的地址做不同解读

我们不是要直接映射到Cache的块上吗？那我们高位和低位的含义不变，中间的若干位作为映射到的块号不就好了吗？

还是拿地址 0xFF0114 来举例子，Cache块数为8，块长32字节

![image-20220501162428541](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220501162428541.png)

所以低位还是5位，块数为8，那中间位数为3，记中间位为行号，剩余高位作为标签

那这样我们就不需要CAM去比较有没有这个块了，主存块到Cache块的映射已经给出了，就是中间位的数字，行号，那我们只要到这一行去看看当前Cache这一行存的块是不是我们要找的块就行了

![image-20220501163839994](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220501163839994.png)

从直接映射Cache读出的过程：读入地址，读入地址的行号，到Cache该行号的地方比对标签，相同的话说明命中，偏移“偏移量”后读出访问的对象，不同的话说明缺失，要从主存读入

##### 组相连映像

上面两种方法都不行，那我们折中一下行不行？

我们把Cache的块分一下组，组内全相联，组间直接映像。即主存的块只能映射到某个组，组内的块随便映射

这样就能调整全相联和直接映像的含量了。如果组有Cache块数那么大，那么就是全相联；如果组只有一个块那么大，那么就是直接映像

映像方式就是：映像到的组号=主存的块号  mod  组号总数

那这样还是要用到替换算法

那具体实现呢？

还是套用之前的模板

直接映射的行号不是具体到行吗？那如果我们把行号的若干位分给标签位，这样不就相当于把行分组了吗？

所以这时的行号位就是组号位，组号位有行号位那么长，就是直接映射，组号位长度为0，那就是一个组，全相联映射

![image-20220501164731510](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220501164731510.png)

从组相联映射Cache读出过程：读入地址，读入组号，到Cache对应的组用CAM找出Cache数据中的地址，再偏移就好了

之前已经举过这个例子了，如下图

![image-20220501172258666](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220501172258666.png)

一组有4个块，所以是4路。用组号找到组的地址，同时读出标签比对，然后4选1输出，最后偏移（是不是最后偏移不清楚）

#### 替换算法

- 随机算法（RAND)

  随机替换，显然不合理

- 先进先出（FIFO）算法

  所能放的块中，最早进入的块被替换

  容易实现，系统开销小，但经常使用的块可能会被替换

- 近期最少使用（LRU）算法

  最少被使用的块被替换，相对合理，但系统开销大

- 最久未使用（LRU）算法

  最久未访问的块被替换

#### 更新策略

即写入Cache后何时写入主存的策略

这里介绍之前提到的写直达法和写回法

- 写直达法

  数据同时写入Cache和主存，后面Cache的块要替换时就直接替换，不用管其他

  好处是实现简单，数据正确

  缺点是写入主存过于频繁，多次传送块导致存取速度下降

- 写回法

  只写入Cache，不写入主存，仅当替换该块时，更改过的话写入主存

  这样Cache块要有一个标志位，修改后标志位置“1”，如下图

  ![image-20220501173757230](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220501173757230.png)

  d就是修改标志位

  好处是操作速度快

  缺点是主存的块可能还没来得及修改而出错

## 虚拟存储器

这部分到操作系统的相应部分去看

# 第四章——指令系统

## 指令格式

一般指令分为操作码和地址码两部分

![image-20220811163450434](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220811163450434.png)

- 操作码指明该指令执行何种操作
- 地址码给出要操作的数据的地址（虽然后面有立即寻址地址码直接表示数据），可以认为指令根据地址码给出的数据进行操作，而不局限于地址这个概念

## 一些概念

指令字长

- 就是这个指令的位数
- 单字长指令：指令字长等于机器字长的指令
- 双字长，半字长指令：同上规则
- 定长指令字结构：所有指令长度相等
- 变长指令字结构：根据功能而不同长度，因为主存是按字节编址的，所以一般长度都为字节的整数倍

指令的几种格式

- 零地址指令
- 一地址指令
- 二地址指令
- 三地址指令
- 四地址指令

扩展指令操作码格式

- 变长操作码的一种实现方法（不是变长指令字，是操作码不是固定的）
- 地址占用完了，剩余的就是操作码的长度，所以地址数越多，操作码长度越短。我们从操作码短的所能表示的范围踢出若干个数作为长一点操作码的标志，比如三地址指令操作码长4，二地址指令操作码长10，那么在0000~1111的范围内，我选0000，0010，1111作为二地址指令的标志，这样二地址指令就有了$$3\times 2^{(10-4)}$$条，同理，我们再从二地址指令操作码的范围中踢出若干个数，这样一地址指令的操作码也有范围了

## 指令寻址和数据寻址

冯诺依曼体系中，指令和数据都是存在存储器中的，所以我们要执行指令，就要先找到指令，要使用数据，就要找到数据，这就是指令寻址和数据寻址

## 指令寻址

指令的执行在读出一条指令后，PC计数器就会加一（必定加一）（另外这个“一”是指一条指令，也就是说一条指令的字长为3，那么PC加3），这个就称为顺序寻址

一条指令的执行其实也可以修改PC的值，这样能达到地址跳跃的功能，这个就称为跳跃寻址，实现方式分为以下两种跳跃

- 绝对寻址，直接把PC改为这个地址。这个看起来寻址范围很难覆盖整个存储器，实际上也是，那怎么办？对于定长指令字结构，指令的字长都固定，那字长假如有4字节，那么其实绝对寻址的地址最后两位不用写，都默认00即可，因为我们不会有不是00的指令地址。但还是不够怎么办？那我们再把PC的高位拿过来补即可。但听起来这样还是不能找到所有的地址，但大部分情况都没问题了（你问我有问题怎么办？我怎么知道）。所以这个情况下的绝对地址为：PC高位+写入的绝对地址+默认的指令字长对应位数00
- 相对寻址，PC加上要去的地址和自己的差值。注意，PC在读一条指令后都加了“一”，之后再相对寻址加上差值，所以是到的地址为：当前指令+“一”+差值

## 数据寻址

数据寻址的寻址方式老多了，所以为了区分各种方式，我们加了一个字段，叫寻址特征

![image-20220815093048966](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220815093048966.png)

另外注意，寻址方式是对一个地址码的解释方式，而不是指某一条指令，整条的寻址方式

### 隐含寻址

即操作数放的地方是默认的一个地方，可以是一个寄存器，或是任何一个可以存储的东西里面

### 立即寻址

即认为地址码就是操作数

当然这样立即数的范围就收到地址码的位数限制了

### 直接寻址

即认为地址码是操作数的地址，要对这个操作数操作的话，按这个地址去找，去改

### 间接寻址

即认为地址码是操作数的多级（包括二级）指针，间接的意思是不能直接按这个地址找到

优点是寻址范围大多了，因为存储器里存的地址位数比指令里地址码的位数长多了

缺点是太慢了，所以不常用，扩大寻址范围也一般不用这种方法

### 寄存器寻址

即认为地址码是寄存器的编号，寄存器里面存了操作数

好处是寄存器的位数长，有效地扩大了寻址范围，且寄存器访问速度很快，不用怕速度问题

坏处是数量有限，价格昂贵

### 寄存器间接寻址

即认为地址码是寄存器的编号，寄存器里存了操作数的地址

### 相对寻址

即认为地址码是偏移值，把这个偏移值加上PC里的值，就是操作数的地址，这样方便找，广泛用于JMP等转移指令

### 基址寻址

即地址码看作偏移值，把这个偏移值加上基址寄存器（可以采用通用寄存器作为基址寄存器，也可以弄一个专用）里的值，就是操作数的地址

这个其实是用于解决操作系统虚拟内存实现的翻译问题的，本质就是我们程序运行时的逻辑地址加上程序在内存中的基址，我们就能完成一个翻译的工作

### 变址寻址

即把地址码看作要访问的一堆逻辑地址的开头，看作基址，再加上变址寄存器（可以用通用寄存器，也可以专门弄一个）里的值，就是操作数的地址

和基址寻址的区别就是我们其实会通过增加变址寄存器的值的方式来达到循环访问，间隔一定距离访问的需求，是面向用户的；而基址寻址只是给出了程序的基址，是面向操作系统的

### 堆栈寻址

即找一个地方作为堆栈，栈顶即操作数所在

用寄存器组组成的堆栈叫硬堆栈，用内存组成的堆栈叫软堆栈

很明显，寄存器组又少又贵，一般都是内存做堆栈

## CISC和RISC概念

CISC就是复杂指令系统计算机

RISC就是精简指令系统计算机

CISC希望通过增加各种复杂冗长的指令，来增加指令系统的能力（能适应更多不同的应用领域）。

- 由此，CISC的指令庞大，所以长度不固定，由此执行时间相差很大，这样流水线技术很难提升效率。
- 并且指令过多，不可能通过硬连线的方式控制，必须通过微程序的方式控制。指令过多，所以难以优化。
- 并且根据局部性原理，大部分指令都是用不到的

RISC希望精简指令，复杂指令由简单指令组合即可。

- 这样的好处是大部分指令能统一在一个时钟周期完成，流水线技术能大大提高效率。
- 精简指令，这样能用更快的硬件完成指令。并且RISC尽量使用“寄存器到寄存器”的指令，只有“存数/取数”指令访问内存（CISC访问内存的指令乱七八糟，太鸡巴多了），这样运行速率更快。
- 精简指令更好优化编译

### CISC和RISC比较

由于CISC是以增加指令的方式发展，所以CISC大多能实现新老系统软件兼容

但RISC精简了指令，可能老机子认为需要的指令新机子没了，各种格式也可能改了，所以新老兼容很多做不到

当然，RISC性能上是优于CISC的，也是未来发展的趋势，虽然早期软件都是根据CISC设计的，所以和RISC无法兼容。但现在CISC也融入了很多RISC的理念，和RISC的差距也在缩小

下面列举RISC优于CISC的地方

- CISC的微程序控制部分占据CPU芯片50%以上，而RISC硬布线只占CPU芯片10%左右，这部分空出来的空间可以用来存放寄存器和其他部件
- RISC采用寄存器到寄存器和流水线的理念，运算速度更快
- RISC设计简单，因而可靠性高，设计周期也短
- 更好优化

## 微程序控制

这里来解释一下这玩意

### 指令周期，机器周期，时钟周期

首先解释一下指令周期，机器周期（CPU周期），时钟周期

指令周期是指执行一条指令所需要的若干个机器周期的时间

机器周期是微指令执行所需要的时间

时钟周期是计算机最小的时间单位，组成了机器周期。在一个时钟周期里面，计算机只能改变一次信号（同步控制方式下，每次改变信号都是只能在一个机器周期固定的某个时钟周期来做），比如改变几个部件的输入信号，但不可能有一个信号，在一个时钟周期改变几次

### 指令，微指令，微命令

我们运行一个程序，实际上是汇编指令的集合，那更深入地问，我们一条mov指令，把一个东西移到另一个东西里，这一条指令难道是一步完成，不可分割的吗？不不不，指令下面还有更小的指令，比如把某寄存器的东西输出到总线上，从总线上读入数据到内存，这些指令组成了一条指令，于是，这些小的指令就叫微指令

那这些微指令还能分割吗？可以！比如把某寄存器的东西输出到总线上，实际上是机器周期中，第一个时钟周期选中对应寄存器，第二个时钟周期寄存器的输出信号有效，输出到总线（这里只是举个例子，并不一定完全是这样做的）。这些控制信号，就是微命令。而微命令的执行过程，就叫微操作

总的来说是这样

时钟周期 } 机器周期 } 指令周期

微命令（控制信号） } 微指令 } 微程序（汇编指令）

所以一条汇编指令的执行，实际上是一直按当前指向的微指令去执行。微指令全存在CPU的存储器中（不是内存，是CPU直属的存储器，用ROM实现，叫控制存储器）。读指令到指令寄存器IR，实际上是执行读汇编指令的微指令。我们从IR读取这条指令，经过译码（译码就是根据指令的某些部分，比如哪几位是1，就指向哪个地址）得到这条汇编指令（微程序）最开头的微指令的地址，转到这个地址，然后计算机执行这条微指令，执行的过程实际上就是读出这条微指令存储的内容，某一位是1，就把对应的控制信号（微命令）输出，一个机器周期过去了，这条微指令又会指向下一条微指令，然后又会跳到下一条微指令，这样就能一条一条执行，到最后一条时，会跳到一个看看中断与否的微指令，然后跳回读取汇编指令的微指令，这样又能读下一条汇编指令

这也是为什么CIRC要一堆空间来存微程序的原因——太多指令，光是存微指令就要一堆空间了

### 水平型和垂直型微指令

另外还有个水平执行和垂直执行的区别，即一条微指令一次能执行多个微命令还是只执行一个微命令

### 微指令编码

- 直接表示法
  - 一个微命令占1比特

- 编码表示法
  - 控制信号这么多，这样微指令都长得一逼，所以我们还可以把微命令分类，很明显，各个部件输出到总线的信号不能同时有效，我们就可以把它们放到一个组里面，用二进制表示哪一个部件的输出信号有效，这样就把这么多数量对数量级地减少了，比如8个互斥信号，用3比特即可表示。当然这样增加了译码的过程

### 微指令的转移方式

前面说是跳转，准确来说有两种跳转

- 计数器方式
  - 就改微指令的微地址寄存器，顺序执行就把这寄存器加一，非顺序执行就要改它
- 多路转移方式
  - 即下一个微指令的微地址可以有多个，由判别测试和状态寄存器等等信息去不同的跳转
  - 实现方式就是微指令中的下一微指令的微地址的某几位（一般是高几位）的取值由状态标志寄存器的值决定或译码后决定，这样就能实现多路转移了

## 硬布线控制

这玩意就没啥好讲的了，就逻辑电路

# 第五章——中央处理器CPU

本来微程序是在这一章讲的，但概念已经在上面介绍过了，下面就介绍一下CPU的组成，指令的执行和流水线技术即可

## CPU的功能

- 指令控制
  - 取指令
  - 分析指令（指令译码）
  - 执行指令
- 操作控制
  - 即把执行指令过程中需要发送的控制信号按规定的时钟周期发送
- 时间控制
  - 使各个信号按规定的时钟周期去做
- 数据加工
  - 对数据进行算数和逻辑运算
- 中断处理
  - 中断是一个很有效的请求机制，就像你希望别人有事自己说，而不是你一个个问一样，某外接设备想要CPU处理，直接请求中断就好了。另外运行过程中出异常状况了（数组越界了之类的），CPU也需要进入中断（不进中断程序就继续运行了，出问题都继续运行，那就更出问题了），在中断里处理这些异常状况，能修复的修复，不能修复的报错停止程序运行

## CPU的基本结构

主要由两部分组成

- 运算器
  - 执行所有算数运算
  - 执行所有逻辑运算，并进行逻辑测试，如零值测试
- 控制器
  - 组成如下
    - 程序计数器（PC）
    - 指令寄存器（IR）
    - 指令译码器
    - 时序产生器
    - 操作控制器
  - 功能如下
    - 从cache取指，并指出下一条指令在cache中的位置
    - 对指令译码，产生想要的操作控制信号，执行指令
    - 控制CPU，cache和输入输入设备的数据流动

## CPU中的主要寄存器

有很多种寄存器，但至少要有以下六种

- 数据缓存寄存器（DR）
  - 暂存ALU的运算结果/内存读出的一个数据字/外部接口的一个数据字
  - 作用是作为ALU和通用寄存器，CPU和内存，外围设备的速度匹配
- 指令寄存器（IR）
  - 保存当前正在执行的一条指令
- 程序计数器（PC）
  - 指出下一条要执行的指令
- 数据地址寄存器（AR）
  - 指出当前访问数据的地址（和PC正好形成指令和数据的对应）
- 通用寄存器（R0~R3）
- 状态字寄存器（PSW）

一般叫寄存器之间传递信息的通路叫数据通路

累加寄存器（ACC）是缓存ALU计算结果的一个通用寄存器

PC和通用寄存器对汇编程序员可见，其他不可见

## 控制方式

这个控制方式是针对微指令的，而不是指令

### 同步控制方式

即每个指令所需要的机器周期数和时钟周期数固定不变（并不意味着机器周期数和时钟周期数统一），这就意味着所有微操作都是按着时钟周期（或者是某一时序）走的，所以是同步

有如下方案

- 每个机器周期的时钟周期数统一，这样简单微操作时间浪费就多
- 每个机器周期的时钟周期数不统一，大多数微操作较短的机器周期完成，少部分较长的机器周期延迟
- 每个机器周期的时钟周期数不统一，但不同上面的是，少部分复杂指令，用另外的时序定时，称为局部控制，而固定的短机器周期，称为中央控制

为什么没有说机器周期数呢？因为控制方式是针对微指令的，它想节省的是微指令的时间，机器周期是由时钟周期数决定的，机器周期的多少，节省不了时间，影响的是流水线

### 异步控制方式

即每个微操作所需要多少时间就用多少时间，用应答的方式进行联络（做完了就说），这样就没有严格按照时钟去走了，所以是异步，好处是快，坏处是电路控制复杂

### 联合控制方式

同步，异步结合，大部分都固定长度的机器周期，难以确定机器周期长度的微操作则以回答作为操作结束

## 流水线技术

指令的执行并非不可分割，执行指令所占用的部件也并非只有一个，如果我们能合理地将指令分割，我们就能在一堆指令时，每个部件都在运算，计算能力就能提高数倍

举个例子，把指令分为取指令（IF），指令译码（ID），执行运算（EX），结果写回（WB）四个阶段，各个阶段的处理速度不一定完全相同，所以在过程之间都需要高速缓冲寄存器，保存上一过程的结果。下面时流水线的时空图

![image-20220818084632355](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220818084632355.png)

![image-20220818084647012](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220818084647012.png)

超标量流水线即每个时钟周期能得到两个微指令的结果

### 流水线分类

上面我们举了指令里流水线技术的应用，其实还有其他地方可以应用

下面时各类流水线

- 指令流水线

- 算数流水线
  - 运算步骤的并行
- 处理机流水线
  - 就是几个处理机构成流水线各个过程

### 流水线的主要问题

很明显，如果指令断流了，没有指令来了，那么流水线的效率就提不上去。更麻烦的是，我们还有一些问题，会导致我们不是没有指令来，而是必须停下等问题处理完成，导致并行不成功。下面介绍这些问题——资源相关，数据相关，控制相关

#### 资源相关

即多条指令在流水线中的同一机器周期征用同一部件的冲突，比如指令和数据都存在同一存储器中，那么取指和访存取数就会冲突

解决方法就是

- 等前面的指令访问完
- 指令和数据存在不同的存储器（数据cache和指令cache）

#### 数据相关

即某条指令就得等前面的指令做完才能做叫数据相关，比如这条指令是拿上一条指令运算的结果，如果上一条指令还没做完，这条指令已经拿了，这样就算错了

下面列举三类数据冲突

- 写后读（RAW）相关
  - 即正确的流程是先写后读
- 读后写（WAR）相关
- 写后写（WAW）相关

解决方法就是

- 遇到数据相关的指令就暂停后面的指令一到几个时钟周期，直到冲突消失
- 数据旁路技术，即本来是上一条指令算完的结果存到寄存器组后，这条指令从寄存器组读，那我们就让这条指令直接到ALU里读，这样就不用等结果存到寄存器组了
- 编译优化，调整指令顺序消除数据冲突

#### 控制相关

就是之前说的，条件跳转指令失败的话，那已经装入，执行的后续指令就废弃了，这样就断流了

解决方法如下

- 延迟转移法，即我后面装入的是和转移指令无关的指令，这样损失的时间片能得到有效利用
- 转移预测法，根据过去行为预测将来，这样就减少预测错的几率

### 流水线的性能指标

性能指标有吞吐率，加速比，效率

#### 吞吐率

吞吐率这词表示的是实际速度的意思，就像理想速度是什么什么，但在实际应用中，总会有各种各样的问题，这就是吞吐率的意义

下面给流水线吞吐率的定义

- n是任务数（也可以理解为一条指令）
- T是处理完n条指令所用的时间
- TP是吞吐率
- $$TP= \frac{n}{T} $$

假设一条指令分为k段，每段耗时相等，为t，且每段之间的高速寄存器消耗的时间忽略

- 则$$T=(k+n-1)t$$
- $$TP=\frac{n}{(k+n-1)t}$$
- 当$$n \rightarrow \infty$$时，$$TP\rightarrow \frac{n}{t}$$

看起来指令分的段数越多，流水线的吞吐率就越高，但是我们忽略了每段之间的高速寄存器的耗时，我们把高速寄存器的耗时记为r

然后流水线的每段耗时要比较接近，不然就会有一段耗时过久，别的部分就断流，他那就堵塞。所以我们认为每段耗时相等（你快你也得给我等着），所以要以耗时最久的那一段(记为$$t_{max}$$)加上高速寄存器的耗时，则

- $$t=t_{max}+r$$

所以是不可能无限提高的，分太多段反而会增加指令本身耗时

另外，分段越多，段与段之间的联系也就越紧密，发生各种资源，数据，控制相关的概率也就大大提升，这样断流可能反而降低了吞吐率

#### 加速比

即不用流水线所用时间和用流水线所用时间之比

- $$T_0$$为不用流水线所用时间
- $$T_k$$为用流水线所用时间
- $$S$$为加速比
- $$S=\frac{T_0}{T_K}$$

那咱们还是可以用分段的角度来看

- $$T_0=nkt$$
- $$T_k=(k+n-1)t$$
- $$S=\frac{nk}{k+n-1}$$
- 当$$n\rightarrow\infty$$时，$$S\rightarrow k$$

可以看出最大加速比就是分段数

#### 效率（这玩意课件没说）

就是时空图里指令的面积和除以整个矩形的面积，叫效率（我觉得这个概念挺无语的）

![image-20220820232907785](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220820232907785.png)

# 第六章——总线

我们计算机总要外接设备的，那设备怎么和CPU交互，传递信息呢？一开始就是一个设备和CPU连一条线，但这样线太多了，CPU也没有这么多接口给你用

所以我们还是回到原来的想法，时分复用，线总不会时刻占满的，就算占满了，我们只要让每个设备平均共享带宽就好了，大不了大家慢一点嘛

这就是总线，大家一起用的想法，特点就是分时和共享

当然总线不止是外部设备和CPU的连接用到，各种多个东西共享一条线路的概念都可以用到

## 总线的分类

### 片内总线

就芯片内的总线，用于CPU内部寄存器与寄存器之间，寄存器和ALU之间的公共连接线

### 系统总线

即计算机系统内各功能部件（CPU，主存，I/O接口）（可以理解为CPU，主存和所有外部设备）之间相互连接的总线（有的单工，有的双工）

又可以分为以下三类

- 数据总线
- 地址总线
- 控制总线

### 通信总线

即与其他计算机系统或其他系统传递信息的总线，也叫外部总线

## 总线结构

### 单总线结构

即将CPU，主存，I/O设备（通过I/O接口）接在一组总线上

注意，是一组，而不是一根，这组系统总线还可以细分为地址总线，数据总线和控制总线

![image-20220821112338359](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220821112338359.png)

优点很明显，简单，便宜，容易接入新设备

缺点也很明显，带宽低，负载重，不能并行传输

### 双总线结构

即两条总线：一条主存总线，用于CPU，主存，通道（后面几章讲）之间传输数据；另一条I/O总线，用于外部设备和通道之间传输数据

![image-20220821112349304](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220821112349304.png)

优点就是把低速IO和I/O总线分离，让通道去处理了，缺点就是要增加通道等硬件设备

### 三总线结构

三条总线：主存总线，I/O总线，直接内存访问（DMA）总线

![image-20220821112400595](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220821112400595.png)

优点：减少主存和CPU之间交换信息通道的负担

缺点：工作效率比较低（这个暂时还没搞清楚）

## 信息传输方式

### 串行传输

只有一条传输线，长距离传输时就不用考虑多条线之间的同步问题，价格低廉

缺点是速度慢

### 并行传输

多条数据线，每条传输线占一位信息

出于速度和效率的考虑，系统总线上采用的是并行传输

## 接口

设备是不能直接接到CPU的，这样速度匹配，数据格式等等问题都很麻烦，所以提供了接口，CPU和接口之间通过总线连接，I/O设备再和接口进行连接

接口提供了以下功能：控制，缓冲，状态，转换，程序中断

![image-20220821191214273](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220821191214273.png)

后面的总线仲裁应该也用到了接口提供的功能

## 总线仲裁

即哪个设备什么时候能占用总线的仲裁

要兼具优先权（即优先级高的设备能优先获得服务）和公平性（即低优先级的设备不能永远占不到）

### 集中式仲裁

即仲裁的逻辑集中于一个设备上（如CPU）

这样所有的总线请求都得发到这个设备上

有以下三种仲裁方式

#### 链式查询方式

即一个个问（图中BG线询问）要不要占总线。大伙像一条链一样排着，优先级高的设备就会先抢到，抢了就截断BG信号，占着总线（可以理解为图中的数据线，地址线），做完了再从头开始问

![image-20220821192013762](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220821192013762.png)

具体的执行过程是

- BS（BB）（bus busy）表示通知控制部件，现在总线忙
- BR（bus request）表示通知控制部件，现在有请求
- 设备有请求时会输出BR，总线空闲时，控制部件一看到BR，就知道有请求了，就会输出BG去问，抢到BG的就会截断信号，并接管总线，同时输出BS，让控制部件知道总线忙，无视其他设备的请求

优点是

- 简单
- 加入设备容易

缺点是

- 线路有一处出问题了，整个都寄了，对硬件电路故障敏感
- 优先级不能改变，要改就得动硬件
- 优先级高的设备一直抢，会导致后面的设备长期得不到总线使用
- 一个一个传递，这样太鸡巴慢了

#### 计数器定时查询方式

链式查询的升级版，删了BG线，增加了设备地址线

- 设备地址可以理解为每个设备的狗牌号
- 控制部件在总线空闲且有请求时，开始计数，并通过设备地址线向所有设备发送当前计数，计数号和自己的设备地址相等的设备，占有总线，并终止计数，后面的和链式查询差不多

![image-20220821195844690](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220821195844690.png)

这样的好处是计数初始值可以任我们定，初始值为0就和链式一样，为5，那5号设备优先级就最高，这样优先级就可以调整了。而且我们还可以让每次查询从上一次的计数终点开始，循环计数，这样所有设备的优先级就都一样了（为什么链式不能循环？因为链式的BG信号是由控制部件发出的，中途经过的设备记不住上次谁占了，控制部件也不知道谁占了）

#### 独立请求方式

这个最像我们日常操作了，有人向我们请求，如果我们不能及时回应，我们就先把它记在本子上，之后可以回应了，我们就在本子中最高优先级的设备给它去做

硬件实现是

- 每个设备都有独立的BR线，BG线（这样才能分辨出谁的请求，针对某一个进行回应）
- 有请求你就输出BR，之后控制部件会按优先级给你发BG让你占有总线

![image-20220821204330550](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220821204330550.png)

这样响应速度就很快了，不用一直轮，轮到自己是才能响应，且这样优先级就可以由控制部件自己定了，和硬件位置无关了

缺点是一个设备就得一条BR，一条BG，线贼鸡巴多，控制逻辑复杂

#### 三者比较

![image-20220821204353288](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220821204353288.png)

### 分布仲裁方式

这个就没有一个部件来集中仲裁了，大伙有请求就把自己的仲裁号（优先级）发到总线上，然后自己拿回总线上的大伙的号，一看，嘿，比自己的优先级高，行，那自己拿回自己的仲裁号，最后剩下来的那个逼就获得总线的使用权了

当然硬件实现的时候不会真的实现拿回仲裁号，这太傻卵了，也贼浪费资源

那硬件怎么实现的？下面是图

![image-20220821213341091](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220821213341091.png)

发到总线上的是一位一位发的（电路传不了那么快），默认0覆盖1，然后如果线上是0而自己这位也是0，那么传给后面的也是0，会让后面全无效，相当于退出比较。最后一位$$W_0$$能输出1的说明全比较赢了，那么它占有总线

## 总线操作和定时

总线定时就是双方交换数据时的一些时间的约定

### 总线周期

实现一次数据传输所要的时间，分为下面4个阶段

### 总线传输的4个阶段

定义

- 主模块（CPU，DMA等），主要是指那些发起请求，掌控传输的设备，比如CPU要访问主存，这时CPU就是主设备；当然如果其他设备发起请求，选择CPU作为交换信息的目标，那么其他设备就是主设备
- 模块，可认为是外部设备和主存等，是被选中交换信息的设备
- 总线的数据传输是在主模块的控制下进行的，而总线的仲裁即主设备的仲裁

4个阶段

- 申请阶段
  - 主模块现在有空和外部设备交互了，所以主模块发出使用总线的请求，总线仲裁器确定下来哪个主模块可以占用总线
- 寻址阶段
  - 刚才申请的总线的主模块发出要访问的存储器地址（主存的内存单元的地址）或I/O端口地址，启动要交互的模块
- 传数阶段
  - 主模块和模块进行一次数据交换（像是向内存里存一个东西），可单向，也可双向传输（即主模块往模块传，模块往主模块传，同时进行），可以往一个地址存一个数据字，也可猝发传输，往一批地址里传一堆数据字
- 结束阶段
  - 主从模块的有关信息从系统总线上撤除，让出总线

### 总线传输的两种方式

- 同步方式：由统一的时钟控制数据传输
- 异步方式：应答方式传输

#### 同步方式

即一个总线周期由若干个时钟周期组成（这意味着规定好了某种总线周期时间间隔固定），严格按照时钟进行

优点：速度快，控制逻辑简单

缺点：由于强制同步，数据的有效性不能及时检验（是指突然截断数据没传完？），可靠性较差

所以适用于总线长度较短，总线所接部件存取时间接近的系统

#### 异步方式

通过请求和应答（就像计网里的REQ和ACK）来控制，不依赖于时钟，总线周期长度可变

主模块发出请求信号，模块发回应答信号

当然请求信号和应答信号只是个统称，在不同情况下两个信号由具体的含义（就像CPU写内存时，写命令就是请求信号）

运行过程分为以下三种

这三种方式应该是适应一些场合的要求的方式（像是什么你不告诉我你可以访问，我就不能访问一样），而不是像计网那样保证信号正确与否的方式（虽然应该也有增强可靠性的作用）

- 不互锁方式

  - 请求信号和应答信号均只维持一段时间，二者没有约束条件，如图

    ![image-20220821234750712](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220821234750712.png)

  - 例子就是CPU给出写命令一段时间，写命令有效期间写入内存，如图

    ![image-20220821234646286](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220821234646286.png)

- 半互锁方式

  - 发出请求信号后，必须收到应答信号，主模块才能撤销请求信号，进行某些操作，所以应答信号不到，主模块就会互锁；而模块发回应答信号，一段时间后就可以撤回应答信号，所以模块不互锁。所以一方锁，一方不锁，所以是半互锁，如图

    ![image-20220821235212645](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220821235212645.png)

  - 例如多个CPU访问共享存储器，CPU发出访问存储器命令（请求），只有收到存储器未被占用的信号（应答），才能访存

- 全互锁

  - 跟计网的差不多，发出请求，发回应答，还要再发出收到应答的应答（这里和TCP说到的两兵同时发动进攻不可能的问题不一样，TCP确实想让两方断开连接，只是同时断开不可能，但它还是想兼顾两方的，但全互锁只想顾一方，所以没有这个问题），收到应答就撤销请求，收到应答的应答就撤销应答，如图

    ![image-20220822000128315](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220822000128315.png)

  - 这个还没找到例子，感觉没有ARQ机制和计网差得还有点大

#### 半同步方式

有同步时钟，但总线周期可变

实现的方法即增加一条信号线，主模块通过这条信号线得知模块是否准备好，没好就加入等待状态的时钟周期，延长总线周期

#### 分离方式

即模块在准备好数据后才申请总线

# 第七章——I/O系统

有很多常识我这里就不讲了

## 磁盘

工作原理如图

![image-20220822092308944](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220822092308944.png)

可以看到读头确实是只能串行地写数据（实际上我也想不到并行地写的方案）

分类也分很多种

- 可换盘，固定盘
- 可移动磁头，固定磁头（固定磁头就是每个磁道都对应一个磁头，这样就省去了找道时间，当然也更复杂）

下面主要讲温切斯特磁盘机

### 温切斯特磁盘机

可移动磁头，固定盘片，密封，组合式的硬磁盘机，把磁头，盘片，电机等驱动部件乃至读写电路都组装到一起了

优点就是密封，防尘性好，可靠性高（你自己想想，在那么高速的旋转中，磁头和盘片中间卡进灰尘，直接把盘片刮花，信息丢失了）

工作时高速旋转，盘面上回形成气垫，把磁头托起，不会刮到盘片

![image-20220822093423746](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220822093423746.png)

### 硬磁盘机的基本组成

- 磁记录介质
- 驱动器
  - 写入电路，读出电路
  - 读写转换开关
  - 读写磁头，磁头定位伺服系统
- 硬盘控制器
  - 控制逻辑与时序
  - 数据并-串，串-并变换电路

### 磁盘驱动器

这玩意实际就是个磁头寻道的转臂加上转盘片的驱动轴罢了

![image-20220822094105712](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220822094105712.png)

### 磁盘控制器

可以理解为磁盘和主机的接口

主要负责

- 控制外存和主机总线交换数据（成批交换）（是不是一个扇区那样地交换我还不清楚）
- 根据主机命令控制设备操作

实际上就是逻辑控制电路

![image-20220822094441267](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220822094441267.png)

磁盘控制器的逻辑框图（就干事的流程）

![image-20220831004011909](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220831004011909.png)

### 磁盘的信息分布

磁盘上的信息时一块一块存的，每一块都有自己的地址，所以这个地址时这样标记的

磁盘地址：（从高到低位）（最高位其实是设备号）-磁道号（柱面号）-面号--扇区号

为什么磁道号在高位，面号在中间，扇区号在低位呢？（PPT上的顺序和这个不一样，先别信它的）

首先扇区号肯定是最低位的，因为低位变化最多，你访问个8位都要低位都要变8次，但高位几乎很难变，而扇区号是最好变的，盘子一直在转，转一圈就遍历一整圈，自己想想都多少位了

磁道号肯定在最高位，你自己想想，谁放在中间，谁切换的情况就相对较多。那我们肯定希望要花较多时间切换的角色少切换。那换磁道和换面谁更耗时间呢？换磁道需要磁头移动，换面只需要切换磁头，让对应磁头去读就好了。二者切换后都不能保证是自己想要读的扇区，所以等扇区的时间没有差别，那么需要物理移动的换磁道时间就相对较长，所以磁道号放最高位

#### 错位命名

然后注意，由于磁盘是串行读出，然后转换成并行而已。这就导致你一次只读一个面。那我们数据都是存某个柱面的（磁道号+扇区号，数据优先连续存在一个柱面），我们读完了一条扇面的东西，要读另一个扇面的一条东西，如果这个扇面所处的物理位置没有接在上一个扇面后面，那我们又得等一圈半圈才能读出这个扇面的东西，太鸡巴傻逼了。所以我们都是下一个面的扇面，所处的物理位置处于上一个面的扇面的物理位置的后面，这样一圈下来，我就能读完整个柱面，不用多花一点时间在等它转到

#### 交替编号

我们扇区不是按0，1，2，3……这样编号的吗？那按常规逻辑来说，0号扇区靠着的下一个扇区（物理意义上）就应该是1号扇区，但这有个问题，咱扇区是常变的，比如说我读完了0号扇区的柱面，然后要读1号扇区的柱面，但其实两次读扇区之间有一段时间是不能读的，要进行一些数据处理，那如果1号扇区靠着0号扇区，读完0号扇区马上读1号扇区，那对不起，读不出，等过了那个时间，转一圈回来了，才能读出来。这太傻逼了，所以我们不能顺着靠，得间隔着靠，比如0号扇区后面接的是4号扇区，4号后面接的是1号扇区，1号扇区后面接的是5号扇区，那这样就不用间隔一圈的时间，间隔一个扇区的时间，刚好等数据处理完，这样不就完美解决问题了吗？

### 磁盘cache

就是简单的要读磁盘时从磁盘cache读，原理了作用和原来差不多

### 磁盘阵列RAID

这玩意其实不是一个硬盘的技术，而是把多个硬盘组合成一个虚拟硬盘（虚拟的意思为并非真的一张硬盘，而是组合起来，用起来像一个硬盘）的技术

这个技术的优点是

- 传输速率高，有容错功能
- 比起传统的大容量磁盘驱动器，价格更低

有多种RAID技术

#### RAID 0：数据条带方式

![image-20220831165518370](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220831165518370.png)

就是把数据块按盘号去存，这样就可以同时从多个盘读，对于读连续的大量的数据效率就大大提升了。当然这个和之前第三章说的一样，一个盘寄了，那么整套系统就寄了

#### RAID1：镜像方式

![image-20220831165821862](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220831165821862.png)

就是简单的做多份拷贝

当然这样太简单也太傻逼了，空间利用率低，写性能也没有提升，读性能倒是提升了磁盘数的倍数（因为每个盘只要读出一段就好了，比如我0号盘读D0，1号盘读D1，这样速度就提升了），还提升了安全性，但也仅此而已了

#### RAID3：带奇偶校验码的并行传送

![image-20220831170516827](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220831170516827.png)

把数据块分成更小的块（比如图中就把D0分成了D00，D01，D02），在用一个盘存校验码（比如P0就是校验D0的），每次读写的时候就可以用校验码来纠正（我不清楚是否能纠正，但部分磁盘损坏整个系统不会寄，对整体吞吐量影响较小），因为是并行读写的，所以读写速率能有较大提升。

但容易受校验磁盘写速率的限制遇到瓶颈（每个数据都要改校验码的嘛），而且设计复杂

#### RAID5：分布式奇偶校验的独立磁盘结构

![image-20220831171240376](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220831171240376.png)

就在RAID3的思想上改进，把校验信息均匀分布到每个磁盘上，而不是一个磁盘上（图中就是把P0等校验码分布在了斜右对角线上了）

之前我们不是受校验磁盘的写性能的瓶颈的限制吗，那现在我们把校验码分布到了各个磁盘，相当于写校验码的是各个磁盘了，这样校验码的写速率相当于成倍地提升了，性能的瓶颈也暂时得到了解决

当然这样很复杂，磁盘重建也很复杂（我不知道什么是磁盘重建）

#### 各种RAID比较

![image-20220831171702212](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220831171702212.png)

## 磁带和光盘

磁带和磁盘的区别就在于磁盘可以动一动磁头就可以找到对应的信息，但磁带你想找一个东西只能顺序地一个个往下走，所以磁带是顺序访问，磁盘是直接访问

光盘和磁盘的区别在于光盘是用光学性质存储信息的，部分光盘可以以改写

还有一种磁光盘，不管它了

## 显示设备

### CRT显示器

CRT即阴极射线管，我们以前的显示器就是CRT显示器

#### CRT的几个概念

分辨率

- 显示器所能显示的像素个数
- 它取决于显像管荧光粉的颗粒度，荧光屏的尺寸以及CRT 电子束的聚焦能力

灰度级

- 像素点的亮暗差别（黑白）颜色的不同 （彩色）。灰度级越多，图象层次越清楚越逼真 
- 它取决于每个像素对应的刷新存储器的位数以及CRT本身 的性能

刷新

- 电子束打在荧光粉上引起的发光只能维持几 十毫秒的时间。因此必须让电子束反复不断地扫描整个屏幕，该过程称为刷新。刷新频率越高，显示越没有闪烁。至少≥50Hz

刷新存储器（视频存储器、显存）

- 为刷新供信号的存储器。容量取决于分辨率和灰度级。如 $$1024 \times 768$$，32位真彩色，需要$$1024*768*32/8B=3MB$$（这个就是存储器的容量）， 其存取周期必须满足刷新频率的要求。若要求刷新频率为75Hz，则刷新存储器的总带宽为： $$75*3*1024*1024／10^6=235.9296 MB/S$$（这里的M和上面的3MB的M不同，指的是$$10^6$$，而不是$$1024 \times 1024$$）（带宽即指这个刷新存储器需要有这么高的写速率，不然我一秒给了你75个屏幕的信息，你只能写20个，那我的信息不就丢了吗）

随机扫描

- 电子束在需要显示字符和图形的地方扫 描。速度快，图象清晰。驱动系统复杂，价格昂贵

光栅扫描

- 电子束扫描整个屏幕（从上到下，从左到右）
  - 逐行扫描
  - 隔行扫描（电视机采用）

### 字符显示器

![image-20220831174959315](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220831174959315.png)

左边是行号，右边是这一行哪个点显示的16进制表示

还有些乱起八糟的东西不想写了

# 第八章——输入输出系统

这一章本来是上一章的内容，但PPT既然分为了八章，那咱就这样写吧

这一章还和总线那一章关系有一点，但不大，主要是容易弄混

总线仲裁仲裁的是主设备，即发起占用总线的设备，它可以是CPU，也可以是其他可以发起占用总线的设备

但接下来说的程序查询方式也好，中断也好，都是CPU是主设备，然后CPU决定和哪个设备交互的方式

## 程序查询方式

即CPU干着主程序，然后发现该看看外设那边数据处理完了没，准备完了没（就咱也不可能说等外设做完后再回到主程序，肯定是先叫它做，我过一段时间再回来看看做完了没）。然后CPU一看，外设1没准备好，那就看看外设2，外设2准备好了，于是CPU就执行外设2的服务子程序，做完后再看看外设3……

![image-20220902203814578](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220902203814578.png)

![image-20220902203831795](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220902203831795.png)

这样做有个很明显的缺点，就是可能大部分程序都没准备好，但你总得用时间去问它们好了没，太浪费时间了

于是有了下面的程序中断方式

## 程序中断方式

这个思想就很符合实际了，谁准备好了谁说一声

每个设备都有根中断线，连上中断机构，这样可以给设备去发出中断信号（可以是I/O输入，如键盘的输入，打印机缺纸；也可以是定时器引起的中断），这些的实现便是中断的硬件线路

然后还可以把中断的概念用到程序运行，如整除0，溢出，断点，单步跟踪，缺页，用户态到内核态的切换等，这些的实现称为中断服务程序

所以中断既用于硬件上，也用于软件上，或者说既有硬件实现，又有软件实现

然后我们把CPU内部的意外的事件，发生后需要中断处理的事件，称为**异常**，因为在CPU内部，所以又称**内中断**（不可屏蔽），其他的中断便称为**外中断**



### 异常

分为三类

- 故障（fault）
  - 主要是指令译码出现非法操作码；缺段缺页；整除0等问题。有些能解决的，如缺页，调回来就行了，程序可以继续执行；但像是整除0，非法指令的问题，这就不能修复了，程序就得终止，故障也就转化为了终止。（我猜判断为故障时还不能判断为终止，所以整除0才被归为故障）
- 自陷（陷阱，trap）
  - 这玩意就是故意让程序在这停下，去执行一些中断服务程序，自陷指令的，做完这些中断服务程序后会自己回来继续执行指令，就比如操作系统的系统调用
- 终止（abort）
  - 发生了一些事情，导致程序不能运行下去（如断电）的中断，叫做终止，就是用来终止程序运行的

### 中断

中断在未注明的情况下，一般指外中断

### 中断的基本概念

执行过程如下

![image-20220903120058081](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220903120058081.png)

做过计组课设对于开头的关中断就有更深的感悟了，中断本质做的就是在指令执行完毕后跳转到一个地方，那个地方我们就称为中断服务程序，但跳转本身就是LPC，是个控制信号，那我们需要防止此时有其他的控制信号有效（这个实际上由硬件的标志位去控制就行），同时需要防止再次中断，否则我这边还没进中断服务程序，那么你说的多级中断就是放屁，我这边都还没进中断服务程序你怎么可能保存断点，那多级中断就会有些中断根本没法返回，所以需要在开头关中断

保存现场实际上就是保存寄存器，做过计组就知道，我们硬件上实现的只有LPC，即跳转，只保存了断点，寄存器啥的根本没管，所以保存寄存器的任务就落到了程序头上，中断程序需要把寄存器的值放到某个地方，当中断程序执行完成后把寄存器恢复。当然保存恢复现场的过程中肯定不能被别人打断或掺杂进来，所以这个过程都需要在关中断的情况下进行

再简单点来说，在用户进程发出中断指令后，其实它应该发出的是关中断和保存PC两条指令，这两条指令都直接对应硬件，也就是我们计组干的事情，然后进行跳转，也就是中断服务程序寻址，跳到我们要做的中断程序，跳转这一步应该就已经到了内核态了，所以此时由这个中断程序保存的现场，即保存各种寄存器之类的，这个信息保存在哪看操作系统的实现，如下

![image-20221216172146001](%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86.assets/image-20221216172146001.png)

中断程序做完后，恢复现场和屏蔽字，返回，这两步也是中断程序做的，到此，就回到发起中断的程序了。所以总的来说前面保存PC实际上有没有操作系统都能保存（计组课设干的就是这个），而后面保存寄存器是操作系统干的（做计组课设的时候就知道不用保存寄存器），不过关中断指令只有内核态才能用（好像不算是操作系统做的）

![image-20220903121528725](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220903121528725.png)

但多重中断还有个问题，那就是优先级的问题。肯定是有些中断应该优先处理的，那么高优先级的中断应该能在低优先级的中断执行的时候再次中断，而低优先级的中断却不能中断高优先级的中断，这个就称为**中断屏蔽**

中断屏蔽可以硬件实现，也可以软件实现

下面讲一下中断的基本接口（一些寄存器），然后讲一下多级中断的硬件实现

### 中断的基本接口

（做过计组课设对于寄存器的作用就有了更深刻的理解，寄存器干的就是寄存，设备有时候不能持续地发出一个信号，或者说要持续地发出一个信号就要把这个信号存到寄存器里面，这就是寄存器的作用，保存一个信号，到以后给某些地方用）

![image-20220903130223213](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220903130223213.png)

下面讲接口相关的寄存器

- RD
  - 准备就绪标志寄存器，外设执行完成后会发出准备就绪信号，存到RD里
- EI
  - 允许中断寄存器，=1时表示可以允许中断，可以通过软件设置EI的值
- BS
  - 忙信号寄存器，这我真不知道有什么用，个人觉得应该是通知设备去执行的，别管它了
- IM
  - 中断屏蔽寄存器，=1时表示中断屏蔽，可以通过软件设置其值
- IR
  - 中断请求寄存器，=1时表示有中断请求

看起来好像EI和IM重复了，其实不是，EI是允许中断，是开关中断里的；而IM是中断屏蔽，是多级中断里的。如果二者合二为一的话，那我软件的开关中断的逻辑就会很复杂，我开中断还得看看这个玩意是不是被屏蔽了，那这个被屏蔽的信息存在哪呢？本质上你还是得用一个寄存器表示中断屏蔽，那我还不如用了先，免去一堆逻辑。

- IR=EI and RD;
  - 这个表示IR是EI和RD的与，即当设备执行完成，准备就绪了，且允许中断的情况下，把中断请求保存到IR里
  - CPU里有个中断请求寄存的IR（当然也有个指令寄存的IR，咱现在不说它），而这个式子说的IR实际上是每个中断接口的中断请求的输出，每个接口最终都会输出到CPU里的IR，那如果有多个设备同时输出了中断信号，那就会都打到IR里，也就是说只要有中断，IR就会置一，那我们怎么知道是哪个设备请求中断呢？所以我们需要有个规则让抢到这个中断的设备在地址线发出自己的中断向量，没抢到的设备就不能发出自己的中断向量，这个就是我们后面说的串行链式排队电路和多级中断电路的实现
- 中断信号=not IM and IR
  - 这个表示不在中断屏蔽时，有中断请求就发出中断信号。
  - 中断信号还会打回IM，令IM置一，让这条链上的其他设备被中断屏蔽
  - 中断信号发出后还会叫中断向量（就是中断程序的进入地址）逻辑发出中断逻辑，这样就能完成中断跳转了

### 串行链式排队电路

这个其实就和总线的链式查询方式很像。总部发出一个信号，连在链子上的部件一个接一个的接受这个信号，有请求的部件就会截断这个信号，并且发出自己的地址

总线的链式访问信号是BG，在中断里就是INTA

![image-20220903132959535](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220903132959535.png)

下面是具体的电路实现

![image-20220903133129641](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220903133129641.png)

最上面是地址线；中上的框框里的是每个部件的中断向量逻辑，用了输出中断向量的；最下面的是串行优先链，抢到信号就会截断，实现优先级；中下的部分就是发出中断向量的逻辑，在INTA有效，抢到信号，且要中断的设备可以发出自己的中断向量

所以串行链式排队电路只能一级中断，一个设备中断后，必须等它做完后才能再次中断，其他设备可以看作被中断屏蔽了

### 多级中断电路

这个思想就是把串行的改造了一下，我们弄几条串行链，高优先级的链会将低优先级的IM置一，这样就能实现中断屏蔽了。当然，同一条链上的优先级遵循串行链上的优先级，但链上有设备中断了，那链上的其他设备是抢不了中断的（即一条链上的不能嵌套），毕竟都被屏蔽了嘛。如下图，这个中断结构称为二维多级中断结构

![image-20220903134913982](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220903134913982.png)

当然多级中断要保存的东西就多了，每嵌套一次中断，就要多保存一层的寄存器，PC，还需要保存IM，因为高级中断虽然会将低级的IM都置一，但不代表着是时刻置一，只是在进入中断那一刻置一。这就意味着当我们从高级中断回到低级中断时，低级中断因为已经在自己进入中断时设置过IM了，所以低级中断并不能再设置IM，甚至它自己都没法解开自己的IM，所以我们需要保存每一层的中断的IM，在退出一层中断时还原IM，这样才能正常运行

下面是上面多条链的排队优先级逻辑的电路实现（就是上图的最左边的逻辑实现）

![image-20220903142007111](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220903142007111.png)

最下面的就是二维多级中断结构的每一条链的IR和IM摆在一起给你看的

中间就是排队的逻辑，举排队器输出的IR3来说，当IR2和IR1为0，IR3’为1时，IR3才输出。至于为什么不用链式的串行优先逻辑呢？谁知道

## DMA方式

程序执行的结果放于主存，执行程序也是从主存取，CPU只是进行一个运算控制的工作，那么CPU和I/O的数据交换本质上就是主存和设备的数据交换，那我们为什么要设备和CPU交换数据，然后再由CPU放回内存呢？（直接和CPU交换就省得再去内存取了，但需要保护，恢复现场等繁琐的操作，如果我们需要存一堆数据，而不用处理什么，那我们肯定不希望经过CPU）

于是便提出了DMA方式，即外设和内存之间架设一个线路，由DMA控制器管理这个线路。这个主要用于满足高速I/O的传送的要求（中断对于那些低速I/O就比较好用）

其实真正实现的时候根本没有多做一条线路，本质上只是由DMA来管理外设和内存去占用总线罢了，外设把数据打到DMA控制器里，然后DMA控制器通过总线输入内存。然后这个方式称为DMA通道

因为是占用总线，所以DMA要和CPU抢总线

### DMA传送流程

![image-20220903183413849](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220903183413849.png)

![image-20220903151640625](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220903151640625.png)

![image-20220903184658646](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220903184658646.png)

### 传送方式

因为是抢总线的方式，所以我们有几种抢法

- 一种是成组传送方式，CPU让出总线，DMA抢到总线传输完一组数据才让出总线；

  ![image-20220903182632324](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220903182632324.png)

- 一种是周期窃取的方式，CPU做一个周期，DMA做一个周期，当然这样总线申请归还的开销很大；

  ![image-20220903182647736](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220903182647736.png)

- 还有一种是DMA和CPU交替访问内存的方式，即CPU工作周期比内存的存取周期长得多，导致CPU一个工作周期访问完了内存，但CPU本身还得处理很多东西，而此时又可以访问内存了，那DMA就利用这点时间进行访存

  ![image-20220903182707852](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220903182707852.png)

### DMA结构介绍

![image-20220903183440570](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220903183440570.png)

![image-20220903183743655](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220903183743655.png)

最下面是外设，可以给DMA请求触发器发送要往内存里存东西的信号，DMA一看有事要干了，就会跟CPU说一声，叫CPU赶紧让出总线。然后外设的每次传输的数据会暂存到数据缓冲寄存器中，传输数据的起始地址会由CPU存到内存地址计数器中，传送数据块的长度由CPU存到字计数器中，每传一次数据，内存地址计数器加一，字计数器减一（王道的图是加一，先按PPT的来吧），当字计数器减到0时，会发出溢出溢出信号（我也不知道怎么发出的，你就当计数完了就会发出一个信号得了），会叫中断机构发送给CPU中断信号，CPU收到这个中断信号，就会执行DMA的中断服务程序，实际上就是DMA释放总线，恢复CPU的一切权力的操作，这时便可以看作是DMA传送完成了

### 选择型和多路型DMA控制器

DMA还分两种

- 一种是选择型DMA，一段时间只选择一个设备去和内存交换数据，如果同一时间有多个请求，则选择优先级高的
- 另一种是多路型DMA，同时选中多个慢速设备，每个设备以字节交叉的方式进行数据传输，然后优先级高的设备的字节第一个传送

## 通道

通道可以理解为升级版的DMA，而DMA可以理解为广义上的通道

在DMA的时候，DMA虽然沟通了内存和外设，但这个过程CPU还是得给DMA预处理，给它擦屁股，于是我们就想让这个部件的权力进一步地扩大，它能自己处理I/O，自己擦屁股，CPU只要跟它说一声就好了，于是便有了通道

通道可以理解为有一套特别的I/O指令的处理机，这套特别的I/O指令叫通道指令，CPU只要和通道发一条通道指令，通道就可以自己完成后面要干的数据传输的事情，做完了跟CPU汇报就行了，不用CPU擦屁股。另外DMA只能控制一台或少数几台同类设备，但通道可以控制多台不同类的设备

所以通道可以看作DMA的完全升级版，有了指令，有了一套操作，还能操控更多的设备

然后通道又有三种

### 三种通道

- 选择通道（高速通道）
  - 就是一次只选中一个设备去传输数据，然后数据传送时成组（数据块）方式进行的，所以传输数据很快，所以主要用于磁盘
- 字节多路通道
  - 就是多个设备分时复用这个通道，频繁地切换，主要用于多台中低速的设备
- 数组多路通道
  - 就是选择通道和字节多路通道的结合，两种方式都可以使用

### I/O指令和通道指令的区别

![image-20220903185312728](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20220903185312728.png)

## 程序查询、中断、DMA、通道的比较

程序查询就是纯纯的最蠢的方法，每次都要腾出时间去全部问一遍，发现有事就处理

中断就聪明一点，有事你就自己说，说了我帮你处理

DMA就进一步特化一个功能，有些事情不用CPU帮你处理，这些事情就是往内存里存东西，CPU教你怎么做（给你初始化），你自己去做就好了，做完以后我帮你擦屁股（中断服务程序）

通道就在DMA的基础上再特化，往内存里存东西的事情不用CPU教了，CPU说一声要干嘛（给出特定的指令），通道自己就干了，干完和CPU说一声就行





















